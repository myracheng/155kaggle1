{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs155miniproject1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOgpGP787YCVw/sg6wKRJiN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myracheng/155kaggle1/blob/master/d_cs155miniproject1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag5XD4I2Rxvq",
        "colab_type": "code",
        "outputId": "db549378-dccf-4fce-8ca9-ec52f85dac6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQmRLDx0R6nX",
        "colab_type": "code",
        "outputId": "0490b767-ffd7-45a7-e797-eb3953cc0f29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "from zipfile import ZipFile \n",
        "file_name = \"drive/My Drive/train.csv.zip\"\n",
        "  \n",
        "# # opening the zip file in READ mode \n",
        "with ZipFile(file_name, 'r') as zipF: \n",
        "    # printing all the contents of the zip file \n",
        "    zipF.printdir() \n",
        "  \n",
        "    # extracting all the files \n",
        "    print('Extracting all the files now...') \n",
        "    data = zipF.extract('train.csv') \n",
        "    print('Done!')\n",
        "\n",
        "file_name = \"drive/My Drive/test.csv.zip\"\n",
        "  \n",
        "# # opening the zip file in READ mode \n",
        "with ZipFile(file_name, 'r') as zipF: \n",
        "    # printing all the contents of the zip file \n",
        "    zipF.printdir() \n",
        "  \n",
        "    # extracting all the files \n",
        "    print('Extracting all the files now...') \n",
        "    data = zipF.extract('test.csv') \n",
        "    print('Done!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File Name                                             Modified             Size\n",
            "train.csv                                      2020-02-09 10:27:26     77009507\n",
            "Extracting all the files now...\n",
            "Done!\n",
            "File Name                                             Modified             Size\n",
            "test.csv                                       2020-02-09 10:27:26     24378147\n",
            "Extracting all the files now...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8R_QPebR82i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MX0OfRFyR-RB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Split test and train data\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "df_train = train_df\n",
        "df_train['diff'] = (df_train['last_price'] - df_train['mid'])**2\n",
        "df_train['avg_bid'] = (df_train['bid1'] * df_train['bid1vol'] + df_train['bid2'] * df_train['bid2vol'] + df_train['bid3'] * df_train['bid3vol'] + df_train['bid4'] * df_train['bid4vol'] + df_train['bid5'] * df_train['bid5vol']) / (df_train['bid1vol'] + df_train['bid2vol'] + df_train['bid3vol'] + df_train['bid4vol'] + df_train['bid5vol'])\n",
        "df_train['avg_ask'] = (df_train['ask1'] * df_train['ask1vol'] + df_train['ask2'] * df_train['ask2vol'] + df_train['ask3'] * df_train['ask3vol'] + df_train['ask4'] * df_train['ask4vol'] + df_train['ask5'] * df_train['ask5vol']) / (df_train['ask1vol'] + df_train['ask2vol'] + df_train['ask3vol'] + df_train['ask4vol'] + df_train['ask5vol'])\n",
        "df_train['diff_avg_bid'] = (df_train['last_price'] - df_train['avg_bid'])**2\n",
        "df_train['diff_avg_ask'] = (df_train['last_price'] - df_train['avg_ask'])**2\n",
        "df_train['diff_avg_bid_ask'] = (df_train['avg_ask'] - df_train['avg_bid'])**2\n",
        "\n",
        "X = df_train.drop('y', axis=1)\n",
        "y = df_train['y']\n",
        "normalized_X=(X-X.mean())/X.std()\n",
        "df_train = train_df.fillna(0)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# num_samples = 10000\n",
        "# X_train = X_train[:num_samples]\n",
        "# y_train = y_train[:num_samples]\n",
        "# X_test=X_test[:int(num_samples*0.5)]\n",
        "# y_test=y_test[:int(num_samples*0.5)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRElC99GSiSz",
        "colab_type": "code",
        "outputId": "a9f6ff1c-e3dc-45e2-a37f-3e543b666768",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dense, Flatten, MaxPooling2D, Dropout,Activation,LSTM\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEbKt693VmlX",
        "colab_type": "code",
        "outputId": "af07d50a-a2a2-48b1-d1a0-b50fee4c05f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "import numpy as np\n",
        "np.shape(X_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6c396d671b30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPHOW-zcYzCV",
        "colab_type": "code",
        "outputId": "d05f087c-ed5b-432a-83e5-18c5e5e91c6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras import regularizers\n",
        "\n",
        "model_3 = Sequential([\n",
        "    Dense(500, activation='relu',input_shape=(33,)),\n",
        "    Dropout(0.3),\n",
        "    Dense(500, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(500, activation='relu'),\n",
        "    # Dropout(0.3),\n",
        "    # Dense(500, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    # Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid'),\n",
        "])\n",
        "model_3.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "hist_3 = model_3.fit(X_train, y_train,\n",
        "          batch_size=32, epochs=10,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 355428 samples, validate on 236952 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "355428/355428 [==============================] - 62s 173us/step - loss: 0.6261 - acc: 0.6502 - val_loss: 0.6222 - val_acc: 0.6517\n",
            "Epoch 2/10\n",
            "355428/355428 [==============================] - 52s 147us/step - loss: 0.6219 - acc: 0.6534 - val_loss: 0.6204 - val_acc: 0.6536\n",
            "Epoch 3/10\n",
            "355428/355428 [==============================] - 52s 147us/step - loss: 0.6206 - acc: 0.6543 - val_loss: 0.6181 - val_acc: 0.6572\n",
            "Epoch 4/10\n",
            "355428/355428 [==============================] - 51s 145us/step - loss: 0.6199 - acc: 0.6555 - val_loss: 0.6196 - val_acc: 0.6559\n",
            "Epoch 5/10\n",
            "335488/355428 [===========================>..] - ETA: 2s - loss: 0.6196 - acc: 0.6556"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-dcee2f61ff89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m hist_3 = model_3.fit(X_train, y_train,\n\u001b[1;32m     18\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m           validation_data=(X_test, y_test))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HgakdfytuIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Split test and train data\n",
        "df_train = train_df.fillna(0)\n",
        "\n",
        "df_train['diff'] = (df_train['last_price'] - df_train['mid'])\n",
        "df_train['avg_bid'] = (df_train['bid1'] * df_train['bid1vol'] + df_train['bid2'] * df_train['bid2vol'] + df_train['bid3'] * df_train['bid3vol'] + df_train['bid4'] * df_train['bid4vol'] + df_train['bid5'] * df_train['bid5vol']) / (df_train['bid1vol'] + df_train['bid2vol'] + df_train['bid3vol'] + df_train['bid4vol'] + df_train['bid5vol'])\n",
        "df_train['avg_ask'] = (df_train['ask1'] * df_train['ask1vol'] + df_train['ask2'] * df_train['ask2vol'] + df_train['ask3'] * df_train['ask3vol'] + df_train['ask4'] * df_train['ask4vol'] + df_train['ask5'] * df_train['ask5vol']) / (df_train['ask1vol'] + df_train['ask2vol'] + df_train['ask3vol'] + df_train['ask4vol'] + df_train['ask5vol'])\n",
        "df_train['diff_avg_bid'] = (df_train['last_price'] - df_train['avg_bid'])\n",
        "df_train['diff_avg_ask'] = (df_train['last_price'] - df_train['avg_ask'])\n",
        "df_train['diff_avg_bid_ask'] = (df_train['avg_ask'] - df_train['avg_bid'])\n",
        "\n",
        "X = df_train.drop('y', axis=1)\n",
        "y = df_train['y']\n",
        "normalized_X=(X-X.mean())/X.std()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_X, y, test_size=0.4, random_state=0)\n",
        "\n",
        "# num_samples = 10000\n",
        "# X_train = X_train[:num_samples]\n",
        "# y_train = y_train[:num_samples]\n",
        "# X_test=X_test[:int(num_samples*0.5)]\n",
        "# y_test=y_test[:int(num_samples*0.5)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HZ_mU1Lt2F8",
        "colab_type": "code",
        "outputId": "0e6fcbf9-43d0-42f4-f4d1-2c2e456aa2b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "model_3 = Sequential([\n",
        "      Dense(5000, activation='relu',input_shape=(33,)),\n",
        "      Dropout(0.1),\n",
        "      Dense(5000, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(5000, activation='relu'),\n",
        "      Dense(1, activation='sigmoid'),\n",
        "  ])\n",
        "model_3.compile(optimizer='adam',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "hist_3 = model_3.fit(X_train, y_train,\n",
        "            batch_size=32, epochs=10,\n",
        "            validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 355428 samples, validate on 236952 samples\n",
            "Epoch 1/10\n",
            "355428/355428 [==============================] - 226s 637us/step - loss: 0.6224 - acc: 0.6556 - val_loss: 0.6184 - val_acc: 0.6584\n",
            "Epoch 2/10\n",
            "355428/355428 [==============================] - 225s 632us/step - loss: 0.6171 - acc: 0.6603 - val_loss: 0.6137 - val_acc: 0.6639\n",
            "Epoch 3/10\n",
            "355428/355428 [==============================] - 225s 632us/step - loss: 0.6157 - acc: 0.6616 - val_loss: 0.6148 - val_acc: 0.6622\n",
            "Epoch 4/10\n",
            "355428/355428 [==============================] - 225s 633us/step - loss: 0.6153 - acc: 0.6627 - val_loss: 0.6135 - val_acc: 0.6637\n",
            "Epoch 5/10\n",
            "355428/355428 [==============================] - 224s 631us/step - loss: 0.6154 - acc: 0.6630 - val_loss: 0.6149 - val_acc: 0.6597\n",
            "Epoch 6/10\n",
            "355428/355428 [==============================] - 224s 630us/step - loss: 0.6146 - acc: 0.6635 - val_loss: 0.6146 - val_acc: 0.6637\n",
            "Epoch 7/10\n",
            "355428/355428 [==============================] - 224s 631us/step - loss: 0.6135 - acc: 0.6639 - val_loss: 0.6130 - val_acc: 0.6632\n",
            "Epoch 8/10\n",
            "355428/355428 [==============================] - 224s 629us/step - loss: 0.6133 - acc: 0.6637 - val_loss: 0.6117 - val_acc: 0.6626\n",
            "Epoch 9/10\n",
            "355428/355428 [==============================] - 224s 629us/step - loss: 0.6134 - acc: 0.6640 - val_loss: 0.6124 - val_acc: 0.6634\n",
            "Epoch 10/10\n",
            "355428/355428 [==============================] - 224s 630us/step - loss: 0.6130 - acc: 0.6646 - val_loss: 0.6118 - val_acc: 0.6652\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAi7pjkty7lQ",
        "colab_type": "code",
        "outputId": "07370b24-1884-4903-e209-4c63fca3104e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "model_3 = Sequential([\n",
        "      Dense(5000, activation='relu',input_shape=(33,)),\n",
        "      Dropout(0.1),\n",
        "      Dense(5000, activation='relu',kernel_regularizer=regularizers.l2(0.01)),\n",
        "      Dropout(0.1),\n",
        "      Dense(5000, activation='relu',kernel_regularizer=regularizers.l2(0.01)),\n",
        "      Dense(1, activation='sigmoid'),\n",
        "  ])\n",
        "model_3.compile(optimizer='adam',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "hist_3 = model_3.fit(X_train, y_train,\n",
        "            batch_size=32, epochs=10,\n",
        "            validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 355428 samples, validate on 236952 samples\n",
            "Epoch 1/10\n",
            "355428/355428 [==============================] - 289s 813us/step - loss: 0.7026 - acc: 0.6531 - val_loss: 0.6270 - val_acc: 0.6584\n",
            "Epoch 2/10\n",
            "355428/355428 [==============================] - 288s 809us/step - loss: 0.6268 - acc: 0.6566 - val_loss: 0.6268 - val_acc: 0.6617\n",
            "Epoch 3/10\n",
            "355428/355428 [==============================] - 287s 809us/step - loss: 0.6250 - acc: 0.6576 - val_loss: 0.6263 - val_acc: 0.6551\n",
            "Epoch 4/10\n",
            "355428/355428 [==============================] - 288s 809us/step - loss: 0.6245 - acc: 0.6584 - val_loss: 0.6215 - val_acc: 0.6604\n",
            "Epoch 5/10\n",
            "355428/355428 [==============================] - 288s 810us/step - loss: 0.6233 - acc: 0.6596 - val_loss: 0.6206 - val_acc: 0.6612\n",
            "Epoch 6/10\n",
            "355428/355428 [==============================] - 288s 809us/step - loss: 0.6225 - acc: 0.6596 - val_loss: 0.6204 - val_acc: 0.6605\n",
            "Epoch 7/10\n",
            " 97600/355428 [=======>......................] - ETA: 3:14 - loss: 0.6220 - acc: 0.6589"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iNbp0LxoCJo",
        "colab_type": "code",
        "outputId": "df37de38-ac37-49d5-b4c9-219caff914b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras import regularizers\n",
        "\n",
        "models = []\n",
        "for d1 in np.arange(0.1,0.6,0.2):\n",
        "  # for d2 in np.arange(0.1,0.6,0.1):\n",
        "  for num_hidden_units in np.arange(4000,8000,1500):\n",
        "    model_3 = Sequential([\n",
        "        Dense(num_hidden_units, activation='relu',input_shape=(33,)),\n",
        "        Dropout(d1),\n",
        "        Dense(num_hidden_units, activation='relu'),\n",
        "        Dropout(d1),\n",
        "        Dense(num_hidden_units, activation='relu'),\n",
        "        Dense(1, activation='sigmoid'),\n",
        "    ])\n",
        "    print(d1)\n",
        "    print(num_hidden_units)\n",
        "    model_3.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    hist_3 = model_3.fit(X_train, y_train,\n",
        "              batch_size=32, epochs=10,\n",
        "              validation_data=(X_test, y_test))\n",
        "    models.append(model_3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1\n",
            "4000\n",
            "Train on 355428 samples, validate on 236952 samples\n",
            "Epoch 1/10\n",
            "355428/355428 [==============================] - 163s 457us/step - loss: 0.6274 - acc: 0.6490 - val_loss: 0.6238 - val_acc: 0.6497\n",
            "Epoch 2/10\n",
            "355428/355428 [==============================] - 162s 456us/step - loss: 0.6228 - acc: 0.6529 - val_loss: 0.6200 - val_acc: 0.6574\n",
            "Epoch 3/10\n",
            "355428/355428 [==============================] - 162s 455us/step - loss: 0.6213 - acc: 0.6550 - val_loss: 0.6192 - val_acc: 0.6542\n",
            "Epoch 4/10\n",
            "355428/355428 [==============================] - 162s 455us/step - loss: 0.6204 - acc: 0.6560 - val_loss: 0.6208 - val_acc: 0.6559\n",
            "Epoch 5/10\n",
            "355428/355428 [==============================] - 162s 455us/step - loss: 0.6199 - acc: 0.6561 - val_loss: 0.6180 - val_acc: 0.6573\n",
            "Epoch 6/10\n",
            "355428/355428 [==============================] - 162s 457us/step - loss: 0.6194 - acc: 0.6568 - val_loss: 0.6195 - val_acc: 0.6552\n",
            "Epoch 7/10\n",
            "355428/355428 [==============================] - 162s 455us/step - loss: 0.6186 - acc: 0.6571 - val_loss: 0.6181 - val_acc: 0.6587\n",
            "Epoch 8/10\n",
            "355428/355428 [==============================] - 162s 456us/step - loss: 0.6185 - acc: 0.6574 - val_loss: 0.6170 - val_acc: 0.6580\n",
            "Epoch 9/10\n",
            "355428/355428 [==============================] - 162s 457us/step - loss: 0.6182 - acc: 0.6576 - val_loss: 0.6175 - val_acc: 0.6561\n",
            "Epoch 10/10\n",
            "355428/355428 [==============================] - 162s 457us/step - loss: 0.6182 - acc: 0.6580 - val_loss: 0.6167 - val_acc: 0.6575\n",
            "0.1\n",
            "5500\n",
            "Train on 355428 samples, validate on 236952 samples\n",
            "Epoch 1/10\n",
            "355428/355428 [==============================] - 277s 779us/step - loss: 0.6279 - acc: 0.6498 - val_loss: 0.6239 - val_acc: 0.6517\n",
            "Epoch 2/10\n",
            "355428/355428 [==============================] - 275s 774us/step - loss: 0.6230 - acc: 0.6535 - val_loss: 0.6194 - val_acc: 0.6568\n",
            "Epoch 3/10\n",
            "355428/355428 [==============================] - 275s 774us/step - loss: 0.6215 - acc: 0.6549 - val_loss: 0.6206 - val_acc: 0.6560\n",
            "Epoch 4/10\n",
            "355428/355428 [==============================] - 276s 776us/step - loss: 0.6205 - acc: 0.6553 - val_loss: 0.6187 - val_acc: 0.6581\n",
            "Epoch 5/10\n",
            "355428/355428 [==============================] - 275s 775us/step - loss: 0.6199 - acc: 0.6556 - val_loss: 0.6216 - val_acc: 0.6566\n",
            "Epoch 6/10\n",
            "355428/355428 [==============================] - 276s 776us/step - loss: 0.6198 - acc: 0.6562 - val_loss: 0.6179 - val_acc: 0.6590\n",
            "Epoch 7/10\n",
            "355428/355428 [==============================] - 275s 774us/step - loss: 0.6192 - acc: 0.6572 - val_loss: 0.6182 - val_acc: 0.6582\n",
            "Epoch 8/10\n",
            "355428/355428 [==============================] - 274s 772us/step - loss: 0.6189 - acc: 0.6574 - val_loss: 0.6176 - val_acc: 0.6553\n",
            "Epoch 9/10\n",
            "355428/355428 [==============================] - 276s 777us/step - loss: 0.6183 - acc: 0.6578 - val_loss: 0.6170 - val_acc: 0.6573\n",
            "Epoch 10/10\n",
            "355428/355428 [==============================] - 278s 781us/step - loss: 0.6186 - acc: 0.6573 - val_loss: 0.6187 - val_acc: 0.6591\n",
            "0.1\n",
            "7000\n",
            "Train on 355428 samples, validate on 236952 samples\n",
            "Epoch 1/10\n",
            "355428/355428 [==============================] - 420s 1ms/step - loss: 0.6299 - acc: 0.6480 - val_loss: 0.6228 - val_acc: 0.6472\n",
            "Epoch 2/10\n",
            "355428/355428 [==============================] - 418s 1ms/step - loss: 0.6242 - acc: 0.6528 - val_loss: 0.6197 - val_acc: 0.6550\n",
            "Epoch 3/10\n",
            "355428/355428 [==============================] - 418s 1ms/step - loss: 0.6219 - acc: 0.6530 - val_loss: 0.6194 - val_acc: 0.6571\n",
            "Epoch 4/10\n",
            "355428/355428 [==============================] - 419s 1ms/step - loss: 0.6213 - acc: 0.6550 - val_loss: 0.6206 - val_acc: 0.6523\n",
            "Epoch 5/10\n",
            "355428/355428 [==============================] - 419s 1ms/step - loss: 0.6202 - acc: 0.6561 - val_loss: 0.6188 - val_acc: 0.6572\n",
            "Epoch 6/10\n",
            "355428/355428 [==============================] - 419s 1ms/step - loss: 0.6204 - acc: 0.6564 - val_loss: 0.6181 - val_acc: 0.6565\n",
            "Epoch 7/10\n",
            "355428/355428 [==============================] - 419s 1ms/step - loss: 0.6199 - acc: 0.6563 - val_loss: 0.6180 - val_acc: 0.6582\n",
            "Epoch 8/10\n",
            "355428/355428 [==============================] - 420s 1ms/step - loss: 0.6195 - acc: 0.6562 - val_loss: 0.6193 - val_acc: 0.6571\n",
            "Epoch 9/10\n",
            "355428/355428 [==============================] - 419s 1ms/step - loss: 0.6193 - acc: 0.6568 - val_loss: 0.6184 - val_acc: 0.6583\n",
            "Epoch 10/10\n",
            "355428/355428 [==============================] - 419s 1ms/step - loss: 0.6188 - acc: 0.6578 - val_loss: 0.6165 - val_acc: 0.6596\n",
            "0.30000000000000004\n",
            "4000\n",
            "Train on 355428 samples, validate on 236952 samples\n",
            "Epoch 1/10\n",
            "355428/355428 [==============================] - 167s 469us/step - loss: 0.6305 - acc: 0.6476 - val_loss: 0.6225 - val_acc: 0.6489\n",
            "Epoch 2/10\n",
            "355428/355428 [==============================] - 166s 466us/step - loss: 0.6263 - acc: 0.6509 - val_loss: 0.6208 - val_acc: 0.6532\n",
            "Epoch 3/10\n",
            "355428/355428 [==============================] - 165s 466us/step - loss: 0.6253 - acc: 0.6519 - val_loss: 0.6226 - val_acc: 0.6498\n",
            "Epoch 4/10\n",
            "355428/355428 [==============================] - 166s 467us/step - loss: 0.6243 - acc: 0.6532 - val_loss: 0.6196 - val_acc: 0.6558\n",
            "Epoch 5/10\n",
            "355428/355428 [==============================] - 166s 466us/step - loss: 0.6237 - acc: 0.6537 - val_loss: 0.6200 - val_acc: 0.6543\n",
            "Epoch 6/10\n",
            "355428/355428 [==============================] - 166s 466us/step - loss: 0.6234 - acc: 0.6540 - val_loss: 0.6193 - val_acc: 0.6566\n",
            "Epoch 7/10\n",
            "355428/355428 [==============================] - 165s 465us/step - loss: 0.6230 - acc: 0.6540 - val_loss: 0.6221 - val_acc: 0.6485\n",
            "Epoch 8/10\n",
            "355428/355428 [==============================] - 166s 466us/step - loss: 0.6224 - acc: 0.6543 - val_loss: 0.6199 - val_acc: 0.6548\n",
            "Epoch 9/10\n",
            "355428/355428 [==============================] - 165s 465us/step - loss: 0.6221 - acc: 0.6553 - val_loss: 0.6185 - val_acc: 0.6580\n",
            "Epoch 10/10\n",
            "355428/355428 [==============================] - 166s 466us/step - loss: 0.6224 - acc: 0.6550 - val_loss: 0.6215 - val_acc: 0.6555\n",
            "0.30000000000000004\n",
            "5500\n",
            "Train on 355428 samples, validate on 236952 samples\n",
            "Epoch 1/10\n",
            "355428/355428 [==============================] - 281s 789us/step - loss: 0.6314 - acc: 0.6477 - val_loss: 0.6256 - val_acc: 0.6505\n",
            "Epoch 2/10\n",
            "355428/355428 [==============================] - 279s 784us/step - loss: 0.6272 - acc: 0.6501 - val_loss: 0.6218 - val_acc: 0.6482\n",
            "Epoch 3/10\n",
            "355428/355428 [==============================] - 279s 784us/step - loss: 0.6262 - acc: 0.6515 - val_loss: 0.6230 - val_acc: 0.6479\n",
            "Epoch 4/10\n",
            "355428/355428 [==============================] - 279s 784us/step - loss: 0.6260 - acc: 0.6513 - val_loss: 0.6211 - val_acc: 0.6509\n",
            "Epoch 5/10\n",
            "355428/355428 [==============================] - 279s 785us/step - loss: 0.6254 - acc: 0.6519 - val_loss: 0.6210 - val_acc: 0.6542\n",
            "Epoch 6/10\n",
            "355428/355428 [==============================] - 279s 786us/step - loss: 0.6251 - acc: 0.6521 - val_loss: 0.6209 - val_acc: 0.6481\n",
            "Epoch 7/10\n",
            "355428/355428 [==============================] - 279s 784us/step - loss: 0.6238 - acc: 0.6532 - val_loss: 0.6189 - val_acc: 0.6580\n",
            "Epoch 8/10\n",
            "355428/355428 [==============================] - 278s 784us/step - loss: 0.6235 - acc: 0.6541 - val_loss: 0.6240 - val_acc: 0.6440\n",
            "Epoch 9/10\n",
            "355428/355428 [==============================] - 278s 783us/step - loss: 0.6234 - acc: 0.6539 - val_loss: 0.6246 - val_acc: 0.6438\n",
            "Epoch 10/10\n",
            "355428/355428 [==============================] - 278s 783us/step - loss: 0.6235 - acc: 0.6546 - val_loss: 0.6195 - val_acc: 0.6541\n",
            "0.30000000000000004\n",
            "7000\n",
            "Train on 355428 samples, validate on 236952 samples\n",
            "Epoch 1/10\n",
            "355428/355428 [==============================] - 422s 1ms/step - loss: 0.6343 - acc: 0.6464 - val_loss: 0.6309 - val_acc: 0.6425\n",
            "Epoch 2/10\n",
            "355428/355428 [==============================] - 419s 1ms/step - loss: 0.6284 - acc: 0.6497 - val_loss: 0.6226 - val_acc: 0.6468\n",
            "Epoch 3/10\n",
            "355428/355428 [==============================] - 419s 1ms/step - loss: 0.6271 - acc: 0.6510 - val_loss: 0.6289 - val_acc: 0.6459\n",
            "Epoch 4/10\n",
            "355428/355428 [==============================] - 419s 1ms/step - loss: 0.6262 - acc: 0.6510 - val_loss: 0.6252 - val_acc: 0.6461\n",
            "Epoch 5/10\n",
            "355428/355428 [==============================] - 419s 1ms/step - loss: 0.6251 - acc: 0.6521 - val_loss: 0.6237 - val_acc: 0.6538\n",
            "Epoch 6/10\n",
            "355428/355428 [==============================] - 419s 1ms/step - loss: 0.6246 - acc: 0.6524 - val_loss: 0.6279 - val_acc: 0.6481\n",
            "Epoch 7/10\n",
            "355428/355428 [==============================] - 419s 1ms/step - loss: 0.6240 - acc: 0.6533 - val_loss: 0.6242 - val_acc: 0.6530\n",
            "Epoch 8/10\n",
            "355428/355428 [==============================] - 419s 1ms/step - loss: 0.6229 - acc: 0.6537 - val_loss: 0.6186 - val_acc: 0.6569\n",
            "Epoch 9/10\n",
            "355428/355428 [==============================] - 418s 1ms/step - loss: 0.6237 - acc: 0.6536 - val_loss: 0.6216 - val_acc: 0.6521\n",
            "Epoch 10/10\n",
            "355428/355428 [==============================] - 419s 1ms/step - loss: 0.6230 - acc: 0.6544 - val_loss: 0.6219 - val_acc: 0.6500\n",
            "WARNING:tensorflow:Large dropout rate: 0.5 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.5 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "0.5000000000000001\n",
            "4000\n",
            "Train on 355428 samples, validate on 236952 samples\n",
            "Epoch 1/10\n",
            "355428/355428 [==============================] - 167s 469us/step - loss: 0.6348 - acc: 0.6446 - val_loss: 0.6241 - val_acc: 0.6507\n",
            "Epoch 2/10\n",
            "355428/355428 [==============================] - 165s 464us/step - loss: 0.6289 - acc: 0.6485 - val_loss: 0.6245 - val_acc: 0.6488\n",
            "Epoch 3/10\n",
            "355428/355428 [==============================] - 165s 464us/step - loss: 0.6275 - acc: 0.6494 - val_loss: 0.6209 - val_acc: 0.6525\n",
            "Epoch 4/10\n",
            "355428/355428 [==============================] - 165s 464us/step - loss: 0.6269 - acc: 0.6503 - val_loss: 0.6196 - val_acc: 0.6567\n",
            "Epoch 5/10\n",
            "355428/355428 [==============================] - 165s 464us/step - loss: 0.6258 - acc: 0.6511 - val_loss: 0.6193 - val_acc: 0.6565\n",
            "Epoch 6/10\n",
            "355428/355428 [==============================] - 165s 464us/step - loss: 0.6259 - acc: 0.6525 - val_loss: 0.6202 - val_acc: 0.6561\n",
            "Epoch 7/10\n",
            "355428/355428 [==============================] - 165s 464us/step - loss: 0.6258 - acc: 0.6521 - val_loss: 0.6187 - val_acc: 0.6578\n",
            "Epoch 8/10\n",
            "355428/355428 [==============================] - 165s 464us/step - loss: 0.6251 - acc: 0.6529 - val_loss: 0.6194 - val_acc: 0.6578\n",
            "Epoch 9/10\n",
            "355428/355428 [==============================] - 165s 465us/step - loss: 0.6254 - acc: 0.6529 - val_loss: 0.6195 - val_acc: 0.6555\n",
            "Epoch 10/10\n",
            "355428/355428 [==============================] - 166s 466us/step - loss: 0.6251 - acc: 0.6527 - val_loss: 0.6219 - val_acc: 0.6472\n",
            "WARNING:tensorflow:Large dropout rate: 0.5 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.5 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "0.5000000000000001\n",
            "5500\n",
            "Train on 355428 samples, validate on 236952 samples\n",
            "Epoch 1/10\n",
            "355428/355428 [==============================] - 280s 788us/step - loss: 0.6366 - acc: 0.6440 - val_loss: 0.6268 - val_acc: 0.6434\n",
            "Epoch 2/10\n",
            "355428/355428 [==============================] - 278s 781us/step - loss: 0.6306 - acc: 0.6472 - val_loss: 0.6221 - val_acc: 0.6535\n",
            "Epoch 3/10\n",
            "355428/355428 [==============================] - 277s 779us/step - loss: 0.6297 - acc: 0.6489 - val_loss: 0.6242 - val_acc: 0.6461\n",
            "Epoch 4/10\n",
            "355428/355428 [==============================] - 277s 780us/step - loss: 0.6281 - acc: 0.6493 - val_loss: 0.6227 - val_acc: 0.6508\n",
            "Epoch 5/10\n",
            "355428/355428 [==============================] - 279s 784us/step - loss: 0.6272 - acc: 0.6506 - val_loss: 0.6218 - val_acc: 0.6557\n",
            "Epoch 6/10\n",
            "355428/355428 [==============================] - 278s 783us/step - loss: 0.6271 - acc: 0.6509 - val_loss: 0.6220 - val_acc: 0.6528\n",
            "Epoch 7/10\n",
            "355428/355428 [==============================] - 279s 784us/step - loss: 0.6267 - acc: 0.6512 - val_loss: 0.6211 - val_acc: 0.6526\n",
            "Epoch 8/10\n",
            "355428/355428 [==============================] - 278s 783us/step - loss: 0.6268 - acc: 0.6523 - val_loss: 0.6232 - val_acc: 0.6492\n",
            "Epoch 9/10\n",
            "355428/355428 [==============================] - 278s 783us/step - loss: 0.6266 - acc: 0.6514 - val_loss: 0.6225 - val_acc: 0.6560\n",
            "Epoch 10/10\n",
            "355428/355428 [==============================] - 278s 782us/step - loss: 0.6257 - acc: 0.6513 - val_loss: 0.6192 - val_acc: 0.6548\n",
            "WARNING:tensorflow:Large dropout rate: 0.5 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "0.5000000000000001\n",
            "7000\n",
            "Train on 355428 samples, validate on 236952 samples\n",
            "Epoch 1/10\n",
            "355428/355428 [==============================] - 417s 1ms/step - loss: 0.6398 - acc: 0.6424 - val_loss: 0.6254 - val_acc: 0.6439\n",
            "Epoch 2/10\n",
            "355428/355428 [==============================] - 412s 1ms/step - loss: 0.6347 - acc: 0.6460 - val_loss: 0.6236 - val_acc: 0.6530\n",
            "Epoch 3/10\n",
            "355428/355428 [==============================] - 412s 1ms/step - loss: 0.6335 - acc: 0.6468 - val_loss: 0.6236 - val_acc: 0.6490\n",
            "Epoch 4/10\n",
            " 31648/355428 [=>............................] - ETA: 5:59 - loss: 0.6349 - acc: 0.6452"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-a608ab355789>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     hist_3 = model_3.fit(X_train, y_train,\n\u001b[1;32m     21\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m               validation_data=(X_test, y_test))\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK3sjLNRs5G5",
        "colab_type": "code",
        "outputId": "051a8ea2-2227-4672-ee14-0205e6ea9c4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#conclusion: 0.5 is way too high, 0.3 not  rly good eiher.."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.1, 0.2, 0.3, 0.4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPS0WW4P6dWQ",
        "colab_type": "code",
        "outputId": "5a38d4a6-f531-4689-8351-d9f840e261f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        }
      },
      "source": [
        "from keras import regularizers\n",
        "\n",
        "num_hidden_units = 7000\n",
        "d1 =  0.2\n",
        "d2 = 0.1\n",
        "# models = []\n",
        "model_3 = Sequential([\n",
        "    Dense(num_hidden_units, activation='relu',input_shape=(33,)),\n",
        "    Dropout(d1),\n",
        "    Dense(num_hidden_units, activation='relu'),\n",
        "    Dropout(d2),\n",
        "    Dense(num_hidden_units, activation='relu'),\n",
        "    Dense(1, activation='sigmoid'),\n",
        "])\n",
        "print(d1)\n",
        "print(num_hidden_units)\n",
        "model_3.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "hist_3 = model_3.fit(X_train, y_train,\n",
        "          batch_size=32, epochs=10,\n",
        "          validation_data=(X_test, y_test))\n",
        "models.append(model_3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2\n",
            "7000\n",
            "Train on 473904 samples, validate on 118476 samples\n",
            "Epoch 1/10\n",
            "473904/473904 [==============================] - 537s 1ms/step - loss: 0.6284 - acc: 0.6494 - val_loss: 0.6218 - val_acc: 0.6549\n",
            "Epoch 2/10\n",
            "473904/473904 [==============================] - 534s 1ms/step - loss: 0.6236 - acc: 0.6533 - val_loss: 0.6200 - val_acc: 0.6542\n",
            "Epoch 3/10\n",
            "473904/473904 [==============================] - 534s 1ms/step - loss: 0.6219 - acc: 0.6545 - val_loss: 0.6230 - val_acc: 0.6528\n",
            "Epoch 4/10\n",
            "473904/473904 [==============================] - 535s 1ms/step - loss: 0.6213 - acc: 0.6549 - val_loss: 0.6187 - val_acc: 0.6581\n",
            "Epoch 5/10\n",
            "473904/473904 [==============================] - 534s 1ms/step - loss: 0.6208 - acc: 0.6559 - val_loss: 0.6215 - val_acc: 0.6495\n",
            "Epoch 6/10\n",
            "473904/473904 [==============================] - 535s 1ms/step - loss: 0.6200 - acc: 0.6556 - val_loss: 0.6211 - val_acc: 0.6563\n",
            "Epoch 7/10\n",
            "473904/473904 [==============================] - 534s 1ms/step - loss: 0.6197 - acc: 0.6564 - val_loss: 0.6185 - val_acc: 0.6581\n",
            "Epoch 8/10\n",
            "473904/473904 [==============================] - 534s 1ms/step - loss: 0.6199 - acc: 0.6570 - val_loss: 0.6172 - val_acc: 0.6568\n",
            "Epoch 9/10\n",
            "267680/473904 [===============>..............] - ETA: 3:48 - loss: 0.6193 - acc: 0.6571"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-c3ff3ed1eae7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m hist_3 = model_3.fit(X_train, y_train,\n\u001b[1;32m     21\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m           validation_data=(X_test, y_test))\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX1LTUZt6rGm",
        "colab_type": "code",
        "outputId": "91b5690e-4cf6-4cc4-ede3-7a1042b0c0d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        }
      },
      "source": [
        "#half the hideen units in the subsequent layers\n",
        "num_hidden_units = 7000\n",
        "d1 =  0.2\n",
        "d2 = 0.1\n",
        "# models = []\n",
        "model_3 = Sequential([\n",
        "    Dense(num_hidden_units, activation='relu',input_shape=(33,)),\n",
        "    Dropout(d1),\n",
        "    Dense(int(num_hidden_units/2), activation='relu'),\n",
        "    Dropout(d2),\n",
        "    Dense(int(num_hidden_units/2), activation='relu'),\n",
        "    Dense(1, activation='sigmoid'),\n",
        "])\n",
        "print(d1)\n",
        "print(num_hidden_units)\n",
        "model_3.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "hist_3 = model_3.fit(X_train, y_train,\n",
        "          batch_size=32, epochs=10,\n",
        "          validation_data=(X_test, y_test))\n",
        "models.append(model_3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2\n",
            "7000\n",
            "Train on 473904 samples, validate on 118476 samples\n",
            "Epoch 1/10\n",
            "473904/473904 [==============================] - 232s 490us/step - loss: 0.6267 - acc: 0.6500 - val_loss: 0.6243 - val_acc: 0.6529\n",
            "Epoch 2/10\n",
            "473904/473904 [==============================] - 230s 486us/step - loss: 0.6229 - acc: 0.6533 - val_loss: 0.6195 - val_acc: 0.6556\n",
            "Epoch 3/10\n",
            "473904/473904 [==============================] - 230s 486us/step - loss: 0.6217 - acc: 0.6544 - val_loss: 0.6244 - val_acc: 0.6524\n",
            "Epoch 4/10\n",
            "473904/473904 [==============================] - 231s 487us/step - loss: 0.6210 - acc: 0.6555 - val_loss: 0.6197 - val_acc: 0.6514\n",
            "Epoch 5/10\n",
            "473904/473904 [==============================] - 230s 485us/step - loss: 0.6206 - acc: 0.6554 - val_loss: 0.6190 - val_acc: 0.6574\n",
            "Epoch 6/10\n",
            "473904/473904 [==============================] - 230s 485us/step - loss: 0.6196 - acc: 0.6554 - val_loss: 0.6191 - val_acc: 0.6578\n",
            "Epoch 7/10\n",
            "473904/473904 [==============================] - 230s 486us/step - loss: 0.6195 - acc: 0.6561 - val_loss: 0.6209 - val_acc: 0.6570\n",
            "Epoch 8/10\n",
            "473904/473904 [==============================] - 231s 486us/step - loss: 0.6189 - acc: 0.6563 - val_loss: 0.6186 - val_acc: 0.6549\n",
            "Epoch 9/10\n",
            "120512/473904 [======>.......................] - ETA: 2:47 - loss: 0.6186 - acc: 0.6568"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-25a2190c6d57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m hist_3 = model_3.fit(X_train, y_train,\n\u001b[1;32m     19\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m           validation_data=(X_test, y_test))\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4hP8YDN7cMn",
        "colab_type": "code",
        "outputId": "9307d9e8-8937-4a42-c8b3-a2ff0730616e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "source": [
        "from keras import regularizers\n",
        "from keras.layers import BatchNormalization\n",
        "num_hidden_units = 3500\n",
        "d1 =  0.2\n",
        "d2 = 0.1\n",
        "# models = []\n",
        "model_3 = Sequential([\n",
        "    Dense(num_hidden_units, activation='relu',input_shape=(33,)),\n",
        "    Dropout(d1),\n",
        "    Dense(num_hidden_units, activation='relu'),\n",
        "    Dropout(d2),\n",
        "    Dense(num_hidden_units, activation='relu'),\n",
        "    Dropout(d2),\n",
        "    Dense(num_hidden_units, activation='relu'),\n",
        "    Dense(1, activation='sigmoid'),\n",
        "])\n",
        "print(d1)\n",
        "print(num_hidden_units)\n",
        "model_3.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "hist_3 = model_3.fit(X_train, y_train,\n",
        "          batch_size=32, epochs=10,\n",
        "          validation_data=(X_test, y_test))\n",
        "models.append(model_3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2\n",
            "3500\n",
            "Train on 473904 samples, validate on 118476 samples\n",
            "Epoch 1/10\n",
            " 35872/473904 [=>............................] - ETA: 3:51 - loss: 0.6424 - acc: 0.6455"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-0876076c716d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m hist_3 = model_3.fit(X_train, y_train,\n\u001b[1;32m     23\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m           validation_data=(X_test, y_test))\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFMx42jkWUB7",
        "colab_type": "code",
        "outputId": "80938aab-da81-4316-845c-cbc6c75b786c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        }
      },
      "source": [
        "from keras import regularizers\n",
        "\n",
        "num_hidden_units = 3500\n",
        "d1 =  0.2\n",
        "d2 = 0.1\n",
        "model_3 = Sequential([\n",
        "    Dense(num_hidden_units, activation='relu',input_shape=(33,)),\n",
        "    Dropout(d1),\n",
        "    BatchNormalization(),\n",
        "    Dense(num_hidden_units, activation='relu'),\n",
        "    Dropout(d2),\n",
        "    BatchNormalization(),\n",
        "    Dense(num_hidden_units, activation='relu'),\n",
        "    Dropout(d2),\n",
        "    BatchNormalization(),\n",
        "    Dense(num_hidden_units, activation='relu'),\n",
        "    Dense(1, activation='sigmoid'),\n",
        "])\n",
        "model_3.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "hist_3 = model_3.fit(X_train, y_train,\n",
        "          batch_size=32, epochs=10,\n",
        "          validation_data=(X_test, y_test))\n",
        "models.append(model_3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 473904 samples, validate on 118476 samples\n",
            "Epoch 1/10\n",
            "473904/473904 [==============================] - 277s 584us/step - loss: 5.7535 - acc: 0.6430 - val_loss: 5.7702 - val_acc: 0.6420\n",
            "Epoch 2/10\n",
            "473904/473904 [==============================] - 274s 577us/step - loss: 5.7493 - acc: 0.6433 - val_loss: 5.7702 - val_acc: 0.6420\n",
            "Epoch 3/10\n",
            "137376/473904 [=======>......................] - ETA: 3:08 - loss: 5.7656 - acc: 0.6423"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-3947318bab39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m hist_3 = model_3.fit(X_train, y_train,\n\u001b[1;32m     24\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m           validation_data=(X_test, y_test))\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSzivrd47fjq",
        "colab_type": "code",
        "outputId": "81292462-46c8-4cdc-bf01-65e60609d93f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        }
      },
      "source": [
        "\n",
        "num_hidden_units = 3500\n",
        "d1 =  0.2\n",
        "d2 = 0.1\n",
        "# models = []\n",
        "model_3 = Sequential([\n",
        "    Dense(num_hidden_units, activation='relu',input_shape=(33,)),\n",
        "    Dropout(d1),\n",
        "    Dense(num_hidden_units, activation='relu',kernel_regularizer=regularizers.l2(0.01)),\n",
        "    Dropout(d2),\n",
        "    Dense(num_hidden_units, activation='relu',kernel_regularizer=regularizers.l2(0.01)),\n",
        "    Dropout(d2),\n",
        "    Dense(num_hidden_units, activation='relu',kernel_regularizer=regularizers.l2(0.01)),\n",
        "    Dense(1, activation='sigmoid'),\n",
        "])\n",
        "print(d1)\n",
        "print(num_hidden_units)\n",
        "model_3.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "hist_3 = model_3.fit(X_train, y_train,\n",
        "          batch_size=32, epochs=10,\n",
        "          validation_data=(X_test, y_test))\n",
        "models.append(model_3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2\n",
            "3500\n",
            "Train on 473904 samples, validate on 118476 samples\n",
            "Epoch 1/10\n",
            "473904/473904 [==============================] - 294s 621us/step - loss: 0.7157 - acc: 0.6433 - val_loss: 0.6525 - val_acc: 0.6420\n",
            "Epoch 2/10\n",
            "473904/473904 [==============================] - 292s 616us/step - loss: 0.6517 - acc: 0.6433 - val_loss: 0.6524 - val_acc: 0.6420\n",
            "Epoch 3/10\n",
            "473904/473904 [==============================] - 292s 616us/step - loss: 0.6517 - acc: 0.6433 - val_loss: 0.6523 - val_acc: 0.6420\n",
            "Epoch 4/10\n",
            "473904/473904 [==============================] - 292s 616us/step - loss: 0.6516 - acc: 0.6433 - val_loss: 0.6523 - val_acc: 0.6420\n",
            "Epoch 5/10\n",
            "155552/473904 [========>.....................] - ETA: 3:09 - loss: 0.6520 - acc: 0.6426"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-69e720b4acfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m hist_3 = model_3.fit(X_train, y_train,\n\u001b[1;32m     22\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m           validation_data=(X_test, y_test))\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3jd6eI7mm_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Split test and train data\n",
        "# df_train = train_df.fillna(train_df.median())\n",
        "\n",
        "\n",
        "# df_train['opened_position_qty '].fillna((df_train['transacted_qty']), inplace=True)\n",
        "\n",
        "# df_train['closed_position_qty'].fillna((0), inplace=True)\n",
        "df_train = train_df.fillna(train_df.median())\n",
        "\n",
        "# df_train['closed_position_qty'].fillna((df_train['transacted_qty'] / 2), inplace=True)\n",
        "\n",
        "\n",
        "df_train['diff'] = (df_train['last_price'] - df_train['mid'])\n",
        "df_train['avg_bid'] = (df_train['bid1'] * df_train['bid1vol'] + df_train['bid2'] * df_train['bid2vol'] + df_train['bid3'] * df_train['bid3vol'] + df_train['bid4'] * df_train['bid4vol'] + df_train['bid5'] * df_train['bid5vol']) / (df_train['bid1vol'] + df_train['bid2vol'] + df_train['bid3vol'] + df_train['bid4vol'] + df_train['bid5vol'])\n",
        "df_train['avg_ask'] = (df_train['ask1'] * df_train['ask1vol'] + df_train['ask2'] * df_train['ask2vol'] + df_train['ask3'] * df_train['ask3vol'] + df_train['ask4'] * df_train['ask4vol'] + df_train['ask5'] * df_train['ask5vol']) / (df_train['ask1vol'] + df_train['ask2vol'] + df_train['ask3vol'] + df_train['ask4vol'] + df_train['ask5vol'])\n",
        "df_train['diff_avg_bid'] = (df_train['mid'] - df_train['avg_bid'])\n",
        "df_train['diff_avg_ask'] = (df_train['mid'] - df_train['avg_ask'])\n",
        "#df_train['diff_avg_bid_ask'] = (df_train['avg_ask'] - df_train['avg_bid'])\n",
        "#X = df_train.drop('y', axis=1)\n",
        "X = df_train.drop(['id', 'y', 'bid1', 'bid2', 'bid3', 'bid4', 'bid5', 'ask1', 'ask2','ask3','ask4','ask5'], axis=1)\n",
        "\n",
        "y = df_train['y']\n",
        "normalized_X=(X-X.mean())/X.std()\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_X, y, test_size=0.2, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkZoFYuLoXdk",
        "colab_type": "code",
        "outputId": "63d8474e-df78-461c-c14c-df2c07e82768",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install tensorflow==2.0.0\n",
        "!pip install keras==2.3.1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 53kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.1.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.34.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.11.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.17.5)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.10.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.2)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 56.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.15.0)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 63.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0) (45.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0) (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.16.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.21.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/6d/7aae38a9022f982cf8167775c7fc299f203417b698c27080ce09060bba07/google_auth-1.11.0-py2.py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 12.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.8)\n",
            "\u001b[31mERROR: tensorboard 2.0.2 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.11.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, google-auth, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: google-auth 1.4.2\n",
            "    Uninstalling google-auth-1.4.2:\n",
            "      Successfully uninstalled google-auth-1.4.2\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed google-auth-1.11.0 tensorboard-2.0.2 tensorflow-2.0.0 tensorflow-estimator-2.0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_core",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
            "\r\u001b[K     |▉                               | 10kB 30.3MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20kB 6.7MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30kB 9.1MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40kB 6.1MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 61kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 71kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 81kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92kB 11.2MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 102kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 112kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 122kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 133kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 143kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 153kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 163kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 174kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 184kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 194kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 204kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 215kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 225kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 245kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 256kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 266kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 276kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 286kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 296kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 307kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 317kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 327kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 337kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 348kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 358kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 368kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 378kB 9.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.17.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.12.0)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.2.5\n",
            "    Uninstalling Keras-2.2.5:\n",
            "      Successfully uninstalled Keras-2.2.5\n",
            "Successfully installed keras-2.3.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ErCE-VRdUSe",
        "colab_type": "code",
        "outputId": "cc6fc00e-23ff-47db-e21a-7cfcbfe09ddd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "model_3 = Sequential([\n",
        "      Dense(1000, activation='relu',input_shape=(21,)),\n",
        "      Dropout(0.2),\n",
        "      Dense(500, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(200, activation='relu'),\n",
        "      Dense(1, activation='sigmoid'),\n",
        "  ])\n",
        "model_3.compile(optimizer='adam',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=[auroc])\n",
        "hist_3 = model_3.fit(X_train, y_train,\n",
        "            batch_size=32, epochs=10,\n",
        "            validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 473904 samples, validate on 118476 samples\n",
            "Epoch 1/10\n",
            "473904/473904 [==============================] - 205s 432us/step - loss: 0.6163 - auroc: 0.6578 - val_loss: 0.6128 - val_auroc: 0.6622\n",
            "Epoch 2/10\n",
            "473904/473904 [==============================] - 209s 440us/step - loss: 0.6126 - auroc: 0.6630 - val_loss: 0.6116 - val_auroc: 0.6644\n",
            "Epoch 3/10\n",
            "473904/473904 [==============================] - 208s 438us/step - loss: 0.6116 - auroc: 0.6655 - val_loss: 0.6120 - val_auroc: 0.6650\n",
            "Epoch 4/10\n",
            "473904/473904 [==============================] - 194s 409us/step - loss: 0.6109 - auroc: 0.6661 - val_loss: 0.6114 - val_auroc: 0.6658\n",
            "Epoch 5/10\n",
            "473904/473904 [==============================] - 196s 413us/step - loss: 0.6106 - auroc: 0.6673 - val_loss: 0.6110 - val_auroc: 0.6659\n",
            "Epoch 6/10\n",
            "473904/473904 [==============================] - 188s 398us/step - loss: 0.6105 - auroc: 0.6674 - val_loss: 0.6102 - val_auroc: 0.6664\n",
            "Epoch 7/10\n",
            "473904/473904 [==============================] - 188s 397us/step - loss: 0.6098 - auroc: 0.6686 - val_loss: 0.6119 - val_auroc: 0.6660\n",
            "Epoch 8/10\n",
            "473904/473904 [==============================] - 188s 397us/step - loss: 0.6097 - auroc: 0.6686 - val_loss: 0.6124 - val_auroc: 0.6661\n",
            "Epoch 9/10\n",
            "473904/473904 [==============================] - 191s 402us/step - loss: 0.6095 - auroc: 0.6688 - val_loss: 0.6123 - val_auroc: 0.6647\n",
            "Epoch 10/10\n",
            "473904/473904 [==============================] - 196s 414us/step - loss: 0.6091 - auroc: 0.6697 - val_loss: 0.6109 - val_auroc: 0.6669\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wV29xaGJhT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# probbs = model_3.predict_proba(X_test)\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def auroc(y_true, y_pred):\n",
        "    return tf.py_function(roc_auc_score, (y_true, y_pred), tf.double)\n",
        "\n",
        "# auroc(y_test,probbs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_Ee-Y7AxLOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.shape(df_test.columns)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GHfUiLQlCFW",
        "colab_type": "code",
        "outputId": "06bffd58-db95-4b2c-97bd-e9b6ca9732a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "#predict on test\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "df_test = test_df.fillna(test_df.median())\n",
        "\n",
        "\n",
        "df_test['diff'] = (df_test['last_price'] - df_test['mid'])\n",
        "df_test['avg_bid'] = (df_test['bid1'] * df_test['bid1vol'] + df_test['bid2'] * df_test['bid2vol'] + df_test['bid3'] * df_test['bid3vol'] + df_test['bid4'] * df_test['bid4vol'] + df_test['bid5'] * df_test['bid5vol']) / (df_test['bid1vol'] + df_test['bid2vol'] + df_test['bid3vol'] + df_test['bid4vol'] + df_test['bid5vol'])\n",
        "df_test['avg_ask'] = (df_test['ask1'] * df_test['ask1vol'] + df_test['ask2'] * df_test['ask2vol'] + df_test['ask3'] * df_test['ask3vol'] + df_test['ask4'] * df_test['ask4vol'] + df_test['ask5'] * df_test['ask5vol']) / (df_test['ask1vol'] + df_test['ask2vol'] + df_test['ask3vol'] + df_test['ask4vol'] + df_test['ask5vol'])\n",
        "df_test['diff_avg_bid'] = (df_test['mid'] - df_test['avg_bid'])\n",
        "df_test['diff_avg_ask'] = (df_test['mid'] - df_test['avg_ask'])\n",
        "df_test = df_test.drop(['id', 'bid1', 'bid2', 'bid3', 'bid4', 'bid5', 'ask1', 'ask2','ask3','ask4','ask5'], axis=1)\n",
        "\n",
        "# norm_df = pd.concat([df_test,df_train])\n",
        "# norm_df = (norm_df - norm_df.mean())/norm_df.std()\n",
        "\n",
        "normalized_X_test =(df_test-df_train.mean())/df_train.std()\n",
        "np.shape(df_test.columns)\n",
        "probbs = model_3.predict_proba(normalized_X_test)\n",
        "test_df['Predicted'] = probbs\n",
        "header = [\"id\", \"Predicted\"]\n",
        "test_df.to_csv('output.csv', columns = header,index=False)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-f7af5b89a25e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mnormalized_X_test\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mprobbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized_X_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Predicted'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobbs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Predicted\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_3' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Fi1vgja6o1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df['Predicted'] = probbs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KCns0hR6sYe",
        "colab_type": "code",
        "outputId": "ec6bc344-0fb4-45e2-a6fc-7fe5cb62b261",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(test_df['id'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "191859"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBawXlG061pb",
        "colab_type": "code",
        "outputId": "051c9285-14bd-46d5-ec36-8bae05a2af51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(probbs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "191859"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLdLO8nn63GP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df['Predicted'] = probbs\n",
        "header = [\"id\", \"Predicted\"]\n",
        "test_df.to_csv('output.csv', columns = header,index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYL6OFsh737o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "y = train_df['y']\n",
        "\n",
        "df_train = train_df.fillna(train_df.median())\n",
        "df_train['diff'] = (df_train['last_price'] - df_train['mid'])\n",
        "df_train['avg_bid'] = (df_train['bid1'] * df_train['bid1vol'] + df_train['bid2'] * df_train['bid2vol'] + df_train['bid3'] * df_train['bid3vol'] + df_train['bid4'] * df_train['bid4vol'] + df_train['bid5'] * df_train['bid5vol']) / (df_train['bid1vol'] + df_train['bid2vol'] + df_train['bid3vol'] + df_train['bid4vol'] + df_train['bid5vol'])\n",
        "df_train['avg_ask'] = (df_train['ask1'] * df_train['ask1vol'] + df_train['ask2'] * df_train['ask2vol'] + df_train['ask3'] * df_train['ask3vol'] + df_train['ask4'] * df_train['ask4vol'] + df_train['ask5'] * df_train['ask5vol']) / (df_train['ask1vol'] + df_train['ask2vol'] + df_train['ask3vol'] + df_train['ask4vol'] + df_train['ask5vol'])\n",
        "df_train['diff_avg_bid'] = (df_train['mid'] - df_train['avg_bid'])\n",
        "df_train['diff_avg_ask'] = (df_train['mid'] - df_train['avg_ask'])\n",
        "\n",
        "df_train = df_train.drop(['id', 'y', 'bid1', 'bid2', 'bid3', 'bid4', 'bid5', 'ask1', 'ask2','ask3','ask4','ask5'], axis=1)\n",
        "\n",
        "df_test = test_df.fillna(test_df.median())\n",
        "\n",
        "\n",
        "df_test['diff'] = (df_test['last_price'] - df_test['mid'])\n",
        "df_test['avg_bid'] = (df_test['bid1'] * df_test['bid1vol'] + df_test['bid2'] * df_test['bid2vol'] + df_test['bid3'] * df_test['bid3vol'] + df_test['bid4'] * df_test['bid4vol'] + df_test['bid5'] * df_test['bid5vol']) / (df_test['bid1vol'] + df_test['bid2vol'] + df_test['bid3vol'] + df_test['bid4vol'] + df_test['bid5vol'])\n",
        "df_test['avg_ask'] = (df_test['ask1'] * df_test['ask1vol'] + df_test['ask2'] * df_test['ask2vol'] + df_test['ask3'] * df_test['ask3vol'] + df_test['ask4'] * df_test['ask4vol'] + df_test['ask5'] * df_test['ask5vol']) / (df_test['ask1vol'] + df_test['ask2vol'] + df_test['ask3vol'] + df_test['ask4vol'] + df_test['ask5vol'])\n",
        "df_test['diff_avg_bid'] = (df_test['mid'] - df_test['avg_bid'])\n",
        "df_test['diff_avg_ask'] = (df_test['mid'] - df_test['avg_ask'])\n",
        "df_test = df_test.drop(['id', 'bid1', 'bid2', 'bid3', 'bid4', 'bid5', 'ask1', 'ask2','ask3','ask4','ask5'], axis=1)\n",
        "\n",
        "norm_df = pd.concat([df_test,df_train])\n",
        "norm_test = (df_test - norm_df.mean())/norm_df.std()\n",
        "norm_train = (df_train - norm_df.mean())/norm_df.std()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(norm_train, y, test_size=0.2, random_state=0)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ix6SEJyDwDE0",
        "colab_type": "code",
        "outputId": "d01549ea-279d-4937-c50e-47e5cc86ccae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "model_3 = Sequential([\n",
        "      Dense(1000, activation='relu',input_shape=(21,)),\n",
        "      Dropout(0.2),\n",
        "      Dense(500, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(200, activation='relu'),\n",
        "      Dense(1, activation='sigmoid'),\n",
        "  ])\n",
        "model_3.compile(optimizer='adam',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=[auroc])\n",
        "hist_3 = model_3.fit(X_train, y_train,\n",
        "            batch_size=32, epochs=10,\n",
        "            validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 473904 samples, validate on 118476 samples\n",
            "Epoch 1/10\n",
            "473904/473904 [==============================] - 216s 455us/step - loss: 0.6159 - auroc: 0.6586 - val_loss: 0.6150 - val_auroc: 0.6616\n",
            "Epoch 2/10\n",
            "473904/473904 [==============================] - 215s 454us/step - loss: 0.6126 - auroc: 0.6636 - val_loss: 0.6131 - val_auroc: 0.6627\n",
            "Epoch 3/10\n",
            "473904/473904 [==============================] - 215s 453us/step - loss: 0.6114 - auroc: 0.6655 - val_loss: 0.6120 - val_auroc: 0.6651\n",
            "Epoch 4/10\n",
            "473904/473904 [==============================] - 214s 452us/step - loss: 0.6109 - auroc: 0.6663 - val_loss: 0.6107 - val_auroc: 0.6662\n",
            "Epoch 5/10\n",
            "473904/473904 [==============================] - 215s 454us/step - loss: 0.6103 - auroc: 0.6673 - val_loss: 0.6113 - val_auroc: 0.6657\n",
            "Epoch 6/10\n",
            "473904/473904 [==============================] - 214s 452us/step - loss: 0.6099 - auroc: 0.6680 - val_loss: 0.6108 - val_auroc: 0.6664\n",
            "Epoch 7/10\n",
            "473904/473904 [==============================] - 214s 452us/step - loss: 0.6097 - auroc: 0.6685 - val_loss: 0.6114 - val_auroc: 0.6667\n",
            "Epoch 8/10\n",
            "473904/473904 [==============================] - 207s 438us/step - loss: 0.6093 - auroc: 0.6698 - val_loss: 0.6146 - val_auroc: 0.6655\n",
            "Epoch 9/10\n",
            "473904/473904 [==============================] - 206s 434us/step - loss: 0.6091 - auroc: 0.6694 - val_loss: 0.6105 - val_auroc: 0.6672\n",
            "Epoch 10/10\n",
            "473904/473904 [==============================] - 207s 437us/step - loss: 0.6085 - auroc: 0.6703 - val_loss: 0.6107 - val_auroc: 0.6666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQHyWWvfxrYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "probbs = model_3.predict_proba(norm_test)\n",
        "test_df['Predicted'] = probbs\n",
        "header = [\"id\", \"Predicted\"]\n",
        "test_df.to_csv('output_normtoall.csv', columns = header,index=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYrQp2Fjyaku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}