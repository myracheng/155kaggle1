{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dnn_cs155miniproject1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM88RDjWQKusH4r88kxPhzP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myracheng/155kaggle1/blob/master/dnn2_cs155miniproject1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag5XD4I2Rxvq",
        "colab_type": "code",
        "outputId": "d80815e3-bf26-489a-962c-c5e2e00228ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQmRLDx0R6nX",
        "colab_type": "code",
        "outputId": "b35a018f-b1aa-4167-d95c-6d68068fff0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "from zipfile import ZipFile \n",
        "file_name = \"drive/My Drive/train.csv.zip\"\n",
        "  \n",
        "# # opening the zip file in READ mode \n",
        "with ZipFile(file_name, 'r') as zipF: \n",
        "    # printing all the contents of the zip file \n",
        "    zipF.printdir() \n",
        "  \n",
        "    # extracting all the files \n",
        "    print('Extracting all the files now...') \n",
        "    data = zipF.extract('train.csv') \n",
        "    print('Done!')\n",
        "\n",
        "file_name = \"drive/My Drive/test.csv.zip\"\n",
        "  \n",
        "# # opening the zip file in READ mode \n",
        "with ZipFile(file_name, 'r') as zipF: \n",
        "    # printing all the contents of the zip file \n",
        "    zipF.printdir() \n",
        "  \n",
        "    # extracting all the files \n",
        "    print('Extracting all the files now...') \n",
        "    data = zipF.extract('test.csv') \n",
        "    print('Done!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File Name                                             Modified             Size\n",
            "train.csv                                      2020-02-09 10:27:26     77009507\n",
            "Extracting all the files now...\n",
            "Done!\n",
            "File Name                                             Modified             Size\n",
            "test.csv                                       2020-02-09 10:27:26     24378147\n",
            "Extracting all the files now...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8R_QPebR82i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MX0OfRFyR-RB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Split test and train data\n",
        "df_train = train_df\n",
        "df_train['diff'] = (df_train['last_price'] - df_train['mid'])**2\n",
        "df_train['avg_bid'] = (df_train['bid1'] * df_train['bid1vol'] + df_train['bid2'] * df_train['bid2vol'] + df_train['bid3'] * df_train['bid3vol'] + df_train['bid4'] * df_train['bid4vol'] + df_train['bid5'] * df_train['bid5vol']) / (df_train['bid1vol'] + df_train['bid2vol'] + df_train['bid3vol'] + df_train['bid4vol'] + df_train['bid5vol'])\n",
        "df_train['avg_ask'] = (df_train['ask1'] * df_train['ask1vol'] + df_train['ask2'] * df_train['ask2vol'] + df_train['ask3'] * df_train['ask3vol'] + df_train['ask4'] * df_train['ask4vol'] + df_train['ask5'] * df_train['ask5vol']) / (df_train['ask1vol'] + df_train['ask2vol'] + df_train['ask3vol'] + df_train['ask4vol'] + df_train['ask5vol'])\n",
        "df_train['diff_avg_bid'] = (df_train['last_price'] - df_train['avg_bid'])**2\n",
        "df_train['diff_avg_ask'] = (df_train['last_price'] - df_train['avg_ask'])**2\n",
        "df_train['diff_avg_bid_ask'] = (df_train['avg_ask'] - df_train['avg_bid'])**2\n",
        "\n",
        "X = df_train.drop('y', axis=1)\n",
        "y = df_train['y']\n",
        "normalized_X=(X-X.mean())/X.std()\n",
        "df_train = train_df.fillna(0)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# num_samples = 10000\n",
        "# X_train = X_train[:num_samples]\n",
        "# y_train = y_train[:num_samples]\n",
        "# X_test=X_test[:int(num_samples*0.5)]\n",
        "# y_test=y_test[:int(num_samples*0.5)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb-rCBhY6jZ5",
        "colab_type": "code",
        "outputId": "acb9afde-54ca-4581-b077-5b29a1eb5223",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "source": [
        "aimport matplotlib.pyplot as plt\n",
        "import lightgbm as lgb\n",
        "d_train = lgb.Dataset(X_train, label=y_train)\n",
        "param = {\"max_depth\": 5, \"learning_rate\": 0.1, \"num_leaves\": 900, \"n_estimators\": 100}\n",
        "model2 = lgb.train(params=param,train_set=d_train)\n",
        "# print(‘Plot feature importances…’)\n",
        "ax = lgb.plot_importance(model2, max_num_features=10)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcQAAAEWCAYAAAD4qec7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDohmZmYA/ARBe6Ve8WDAewAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRElC99GSiSz",
        "colab_type": "code",
        "outputId": "28fce168-a287-4b4c-e5a0-b32ed46337d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dense, Flatten, MaxPooling2D, Dropout,Activation,LSTM\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEbKt693VmlX",
        "colab_type": "code",
        "outputId": "435f2946-f96c-4b47-cf0b-787fb5877fd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "import numpy as np\n",
        "np.shape(X_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-6c396d671b30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPHOW-zcYzCV",
        "colab_type": "code",
        "outputId": "d05f087c-ed5b-432a-83e5-18c5e5e91c6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras import regularizers\n",
        "\n",
        "model_3 = Sequential([\n",
        "    Dense(500, activation='relu',input_shape=(33,)),\n",
        "    Dropout(0.3),\n",
        "    Dense(500, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(500, activation='relu'),\n",
        "    # Dropout(0.3),\n",
        "    # Dense(500, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    # Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid'),\n",
        "])\n",
        "model_3.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "hist_3 = model_3.fit(X_train, y_train,\n",
        "          batch_size=32, epochs=10,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 355428 samples, validate on 236952 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "355428/355428 [==============================] - 62s 173us/step - loss: 0.6261 - acc: 0.6502 - val_loss: 0.6222 - val_acc: 0.6517\n",
            "Epoch 2/10\n",
            "355428/355428 [==============================] - 52s 147us/step - loss: 0.6219 - acc: 0.6534 - val_loss: 0.6204 - val_acc: 0.6536\n",
            "Epoch 3/10\n",
            "355428/355428 [==============================] - 52s 147us/step - loss: 0.6206 - acc: 0.6543 - val_loss: 0.6181 - val_acc: 0.6572\n",
            "Epoch 4/10\n",
            "355428/355428 [==============================] - 51s 145us/step - loss: 0.6199 - acc: 0.6555 - val_loss: 0.6196 - val_acc: 0.6559\n",
            "Epoch 5/10\n",
            "335488/355428 [===========================>..] - ETA: 2s - loss: 0.6196 - acc: 0.6556"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-dcee2f61ff89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m hist_3 = model_3.fit(X_train, y_train,\n\u001b[1;32m     18\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m           validation_data=(X_test, y_test))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HgakdfytuIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Split test and train data\n",
        "df_train = train_df.fillna(0)\n",
        "\n",
        "df_train['diff'] = (df_train['last_price'] - df_train['mid'])\n",
        "df_train['avg_bid'] = (df_train['bid1'] * df_train['bid1vol'] + df_train['bid2'] * df_train['bid2vol'] + df_train['bid3'] * df_train['bid3vol'] + df_train['bid4'] * df_train['bid4vol'] + df_train['bid5'] * df_train['bid5vol']) / (df_train['bid1vol'] + df_train['bid2vol'] + df_train['bid3vol'] + df_train['bid4vol'] + df_train['bid5vol'])\n",
        "df_train['avg_ask'] = (df_train['ask1'] * df_train['ask1vol'] + df_train['ask2'] * df_train['ask2vol'] + df_train['ask3'] * df_train['ask3vol'] + df_train['ask4'] * df_train['ask4vol'] + df_train['ask5'] * df_train['ask5vol']) / (df_train['ask1vol'] + df_train['ask2vol'] + df_train['ask3vol'] + df_train['ask4vol'] + df_train['ask5vol'])\n",
        "df_train['diff_avg_bid'] = (df_train['last_price'] - df_train['avg_bid'])\n",
        "df_train['diff_avg_ask'] = (df_train['last_price'] - df_train['avg_ask'])\n",
        "df_train['diff_avg_bid_ask'] = (df_train['avg_ask'] - df_train['avg_bid'])\n",
        "\n",
        "X = df_train.drop('y', axis=1)\n",
        "y = df_train['y']\n",
        "normalized_X=(X-X.mean())/X.std()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_X, y, test_size=0.4, random_state=0)\n",
        "\n",
        "# num_samples = 10000\n",
        "# X_train = X_train[:num_samples]\n",
        "# y_train = y_train[:num_samples]\n",
        "# X_test=X_test[:int(num_samples*0.5)]\n",
        "# y_test=y_test[:int(num_samples*0.5)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HZ_mU1Lt2F8",
        "colab_type": "code",
        "outputId": "0e6fcbf9-43d0-42f4-f4d1-2c2e456aa2b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "model_3 = Sequential([\n",
        "      Dense(5000, activation='relu',input_shape=(33,)),\n",
        "      Dropout(0.1),\n",
        "      Dense(5000, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(5000, activation='relu'),\n",
        "      Dense(1, activation='sigmoid'),\n",
        "  ])\n",
        "model_3.compile(optimizer='adam',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "hist_3 = model_3.fit(X_train, y_train,\n",
        "            batch_size=32, epochs=10,\n",
        "            validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 355428 samples, validate on 236952 samples\n",
            "Epoch 1/10\n",
            "355428/355428 [==============================] - 226s 637us/step - loss: 0.6224 - acc: 0.6556 - val_loss: 0.6184 - val_acc: 0.6584\n",
            "Epoch 2/10\n",
            "355428/355428 [==============================] - 225s 632us/step - loss: 0.6171 - acc: 0.6603 - val_loss: 0.6137 - val_acc: 0.6639\n",
            "Epoch 3/10\n",
            "355428/355428 [==============================] - 225s 632us/step - loss: 0.6157 - acc: 0.6616 - val_loss: 0.6148 - val_acc: 0.6622\n",
            "Epoch 4/10\n",
            "355428/355428 [==============================] - 225s 633us/step - loss: 0.6153 - acc: 0.6627 - val_loss: 0.6135 - val_acc: 0.6637\n",
            "Epoch 5/10\n",
            "355428/355428 [==============================] - 224s 631us/step - loss: 0.6154 - acc: 0.6630 - val_loss: 0.6149 - val_acc: 0.6597\n",
            "Epoch 6/10\n",
            "355428/355428 [==============================] - 224s 630us/step - loss: 0.6146 - acc: 0.6635 - val_loss: 0.6146 - val_acc: 0.6637\n",
            "Epoch 7/10\n",
            "355428/355428 [==============================] - 224s 631us/step - loss: 0.6135 - acc: 0.6639 - val_loss: 0.6130 - val_acc: 0.6632\n",
            "Epoch 8/10\n",
            "355428/355428 [==============================] - 224s 629us/step - loss: 0.6133 - acc: 0.6637 - val_loss: 0.6117 - val_acc: 0.6626\n",
            "Epoch 9/10\n",
            "355428/355428 [==============================] - 224s 629us/step - loss: 0.6134 - acc: 0.6640 - val_loss: 0.6124 - val_acc: 0.6634\n",
            "Epoch 10/10\n",
            "355428/355428 [==============================] - 224s 630us/step - loss: 0.6130 - acc: 0.6646 - val_loss: 0.6118 - val_acc: 0.6652\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAi7pjkty7lQ",
        "colab_type": "code",
        "outputId": "07370b24-1884-4903-e209-4c63fca3104e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "model_3 = Sequential([\n",
        "      Dense(5000, activation='relu',input_shape=(33,)),\n",
        "      Dropout(0.1),\n",
        "      Dense(5000, activation='relu',kernel_regularizer=regularizers.l2(0.01)),\n",
        "      Dropout(0.1),\n",
        "      Dense(5000, activation='relu',kernel_regularizer=regularizers.l2(0.01)),\n",
        "      Dense(1, activation='sigmoid'),\n",
        "  ])\n",
        "model_3.compile(optimizer='adam',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "hist_3 = model_3.fit(X_train, y_train,\n",
        "            batch_size=32, epochs=10,\n",
        "            validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 355428 samples, validate on 236952 samples\n",
            "Epoch 1/10\n",
            "355428/355428 [==============================] - 289s 813us/step - loss: 0.7026 - acc: 0.6531 - val_loss: 0.6270 - val_acc: 0.6584\n",
            "Epoch 2/10\n",
            "355428/355428 [==============================] - 288s 809us/step - loss: 0.6268 - acc: 0.6566 - val_loss: 0.6268 - val_acc: 0.6617\n",
            "Epoch 3/10\n",
            "355428/355428 [==============================] - 287s 809us/step - loss: 0.6250 - acc: 0.6576 - val_loss: 0.6263 - val_acc: 0.6551\n",
            "Epoch 4/10\n",
            "355428/355428 [==============================] - 288s 809us/step - loss: 0.6245 - acc: 0.6584 - val_loss: 0.6215 - val_acc: 0.6604\n",
            "Epoch 5/10\n",
            "355428/355428 [==============================] - 288s 810us/step - loss: 0.6233 - acc: 0.6596 - val_loss: 0.6206 - val_acc: 0.6612\n",
            "Epoch 6/10\n",
            "355428/355428 [==============================] - 288s 809us/step - loss: 0.6225 - acc: 0.6596 - val_loss: 0.6204 - val_acc: 0.6605\n",
            "Epoch 7/10\n",
            " 97600/355428 [=======>......................] - ETA: 3:14 - loss: 0.6220 - acc: 0.6589"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iNbp0LxoCJo",
        "colab_type": "code",
        "outputId": "df37de38-ac37-49d5-b4c9-219caff914b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras import regularizers\n",
        "\n",
        "models = []\n",
        "for d1 in np.arange(0.1,0.6,0.2):\n",
        "  # for d2 in np.arange(0.1,0.6,0.1):\n",
        "  for num_hidden_units in np.arange(4000,8000,1500):\n",
        "    model_3 = Sequential([\n",
        "        Dense(num_hidden_units, activation='relu',input_shape=(33,)),\n",
        "        Dropout(d1),\n",
        "        Dense(num_hidden_units, activation='relu'),\n",
        "        Dropout(d1),\n",
        "        Dense(num_hidden_units, activation='relu'),\n",
        "        Dense(1, activation='sigmoid'),\n",
        "    ])\n",
        "    print(d1)\n",
        "    print(num_hidden_units)\n",
        "    model_3.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    hist_3 = model_3.fit(X_train, y_train,\n",
        "              batch_size=32, epochs=10,\n",
        "              validation_data=(X_test, y_test))\n",
        "    models.append(model_3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1\n",
            "4000\n",
            "Train on 355428 samples, validate on 236952 samples\n",
            "Epoch 1/10\n",
            "355428/355428 [==============================] - 163s 457us/step - loss: 0.6274 - acc: 0.6490 - val_loss: 0.6238 - val_acc: 0.6497\n",
            "Epoch 2/10\n",
            "355428/355428 [==============================] - 162s 456us/step - loss: 0.6228 - acc: 0.6529 - val_loss: 0.6200 - val_acc: 0.6574\n",
            "Epoch 3/10\n",
            "355428/355428 [==============================] - 162s 455us/step - loss: 0.6213 - acc: 0.6550 - val_loss: 0.6192 - val_acc: 0.6542\n",
            "Epoch 4/10\n",
            "355428/355428 [==============================] - 162s 455us/step - loss: 0.6204 - acc: 0.6560 - val_loss: 0.6208 - val_acc: 0.6559\n",
            "Epoch 5/10\n",
            "355428/355428 [==============================] - 162s 455us/step - loss: 0.6199 - acc: 0.6561 - val_loss: 0.6180 - val_acc: 0.6573\n",
            "Epoch 6/10\n",
            "355428/355428 [==============================] - 162s 457us/step - loss: 0.6194 - acc: 0.6568 - val_loss: 0.6195 - val_acc: 0.6552\n",
            "Epoch 7/10\n",
            "355428/355428 [==============================] - 162s 455us/step - loss: 0.6186 - acc: 0.6571 - val_loss: 0.6181 - val_acc: 0.6587\n",
            "Epoch 8/10\n",
            "355428/355428 [==============================] - 162s 456us/step - loss: 0.6185 - acc: 0.6574 - val_loss: 0.6170 - val_acc: 0.6580\n",
            "Epoch 9/10\n",
            "355428/355428 [==============================] - 162s 457us/step - loss: 0.6182 - acc: 0.6576 - val_loss: 0.6175 - val_acc: 0.6561\n",
            "Epoch 10/10\n",
            "355428/355428 [==============================] - 162s 457us/step - loss: 0.6182 - acc: 0.6580 - val_loss: 0.6167 - val_acc: 0.6575\n",
            "0.1\n",
            "5500\n",
            "Train on 355428 samples, validate on 236952 samples\n",
            "Epoch 1/10\n",
            "355428/355428 [==============================] - 277s 779us/step - loss: 0.6279 - acc: 0.6498 - val_loss: 0.6239 - val_acc: 0.6517\n",
            "Epoch 2/10\n",
            "355428/355428 [==============================] - 275s 774us/step - loss: 0.6230 - acc: 0.6535 - val_loss: 0.6194 - val_acc: 0.6568\n",
            "Epoch 3/10\n",
            "355428/355428 [==============================] - 275s 774us/step - loss: 0.6215 - acc: 0.6549 - val_loss: 0.6206 - val_acc: 0.6560\n",
            "Epoch 4/10\n",
            "355428/355428 [==============================] - 276s 776us/step - loss: 0.6205 - acc: 0.6553 - val_loss: 0.6187 - val_acc: 0.6581\n",
            "Epoch 5/10\n",
            "355428/355428 [==============================] - 275s 775us/step - loss: 0.6199 - acc: 0.6556 - val_loss: 0.6216 - val_acc: 0.6566\n",
            "Epoch 6/10\n",
            "355428/355428 [==============================] - 276s 776us/step - loss: 0.6198 - acc: 0.6562 - val_loss: 0.6179 - val_acc: 0.6590\n",
            "Epoch 7/10\n",
            "355428/355428 [==============================] - 275s 774us/step - loss: 0.6192 - acc: 0.6572 - val_loss: 0.6182 - val_acc: 0.6582\n",
            "Epoch 8/10\n",
            "355428/355428 [==============================] - 274s 772us/step - loss: 0.6189 - acc: 0.6574 - val_loss: 0.6176 - val_acc: 0.6553\n",
            "Epoch 9/10\n",
            "355428/355428 [==============================] - 276s 777us/step - loss: 0.6183 - acc: 0.6578 - val_loss: 0.6170 - val_acc: 0.6573\n",
            "Epoch 10/10\n",
            "355428/355428 [==============================] - 278s 781us/step - loss: 0.6186 - acc: 0.6573 - val_loss: 0.6187 - val_acc: 0.6591\n",
            "0.1\n",
            "7000\n",
            "Train on 355428 samples, validate on 236952 samples\n",
            "Epoch 1/10\n",
            "355428/355428 [==============================] - 420s 1ms/step - loss: 0.6299 - acc: 0.6480 - val_loss: 0.6228 - val_acc: 0.6472\n",
            "Epoch 2/10\n",
            "355428/355428 [==============================] - 418s 1ms/step - loss: 0.6242 - acc: 0.6528 - val_loss: 0.6197 - val_acc: 0.6550\n",
            "Epoch 3/10\n",
            "355428/355428 [==============================] - 418s 1ms/step - loss: 0.6219 - acc: 0.6530 - val_loss: 0.6194 - val_acc: 0.6571\n",
            "Epoch 4/10\n",
            "355428/355428 [==============================] - 419s 1ms/step - loss: 0.6213 - acc: 0.6550 - val_loss: 0.6206 - val_acc: 0.6523\n",
            "Epoch 5/10\n",
            "355428/355428 [==============================] - 419s 1ms/step - loss: 0.6202 - acc: 0.6561 - val_loss: 0.6188 - val_acc: 0.6572\n",
            "Epoch 6/10\n",
            "355428/355428 [==============================] - 419s 1ms/step - loss: 0.6204 - acc: 0.6564 - val_loss: 0.6181 - val_acc: 0.6565\n",
            "Epoch 7/10\n",
            "355428/355428 [==============================] - 419s 1ms/step - loss: 0.6199 - acc: 0.6563 - val_loss: 0.6180 - val_acc: 0.6582\n",
            "Epoch 8/10\n",
            "355428/355428 [==============================] - 420s 1ms/step - loss: 0.6195 - acc: 0.6562 - val_loss: 0.6193 - val_acc: 0.6571\n",
            "Epoch 9/10\n",
            "355428/355428 [==============================] - 419s 1ms/step - loss: 0.6193 - acc: 0.6568 - val_loss: 0.6184 - val_acc: 0.6583\n",
            "Epoch 10/10\n",
            "355428/355428 [==============================] - 419s 1ms/step - loss: 0.6188 - acc: 0.6578 - val_loss: 0.6165 - val_acc: 0.6596\n",
            "0.30000000000000004\n",
            "4000\n",
            "Train on 355428 samples, validate on 236952 samples\n",
            "Epoch 1/10\n",
            "355428/355428 [==============================] - 167s 469us/step - loss: 0.6305 - acc: 0.6476 - val_loss: 0.6225 - val_acc: 0.6489\n",
            "Epoch 2/10\n",
            "355428/355428 [==============================] - 166s 466us/step - loss: 0.6263 - acc: 0.6509 - val_loss: 0.6208 - val_acc: 0.6532\n",
            "Epoch 3/10\n",
            "355428/355428 [==============================] - 165s 466us/step - loss: 0.6253 - acc: 0.6519 - val_loss: 0.6226 - val_acc: 0.6498\n",
            "Epoch 4/10\n",
            "355428/355428 [==============================] - 166s 467us/step - loss: 0.6243 - acc: 0.6532 - val_loss: 0.6196 - val_acc: 0.6558\n",
            "Epoch 5/10\n",
            "355428/355428 [==============================] - 166s 466us/step - loss: 0.6237 - acc: 0.6537 - val_loss: 0.6200 - val_acc: 0.6543\n",
            "Epoch 6/10\n",
            "355428/355428 [==============================] - 166s 466us/step - loss: 0.6234 - acc: 0.6540 - val_loss: 0.6193 - val_acc: 0.6566\n",
            "Epoch 7/10\n",
            "355428/355428 [==============================] - 165s 465us/step - loss: 0.6230 - acc: 0.6540 - val_loss: 0.6221 - val_acc: 0.6485\n",
            "Epoch 8/10\n",
            "355428/355428 [==============================] - 166s 466us/step - loss: 0.6224 - acc: 0.6543 - val_loss: 0.6199 - val_acc: 0.6548\n",
            "Epoch 9/10\n",
            "355428/355428 [==============================] - 165s 465us/step - loss: 0.6221 - acc: 0.6553 - val_loss: 0.6185 - val_acc: 0.6580\n",
            "Epoch 10/10\n",
            "355428/355428 [==============================] - 166s 466us/step - loss: 0.6224 - acc: 0.6550 - val_loss: 0.6215 - val_acc: 0.6555\n",
            "0.30000000000000004\n",
            "5500\n",
            "Train on 355428 samples, validate on 236952 samples\n",
            "Epoch 1/10\n",
            "355428/355428 [==============================] - 281s 789us/step - loss: 0.6314 - acc: 0.6477 - val_loss: 0.6256 - val_acc: 0.6505\n",
            "Epoch 2/10\n",
            "355428/355428 [==============================] - 279s 784us/step - loss: 0.6272 - acc: 0.6501 - val_loss: 0.6218 - val_acc: 0.6482\n",
            "Epoch 3/10\n",
            "355428/355428 [==============================] - 279s 784us/step - loss: 0.6262 - acc: 0.6515 - val_loss: 0.6230 - val_acc: 0.6479\n",
            "Epoch 4/10\n",
            "355428/355428 [==============================] - 279s 784us/step - loss: 0.6260 - acc: 0.6513 - val_loss: 0.6211 - val_acc: 0.6509\n",
            "Epoch 5/10\n",
            "355428/355428 [==============================] - 279s 785us/step - loss: 0.6254 - acc: 0.6519 - val_loss: 0.6210 - val_acc: 0.6542\n",
            "Epoch 6/10\n",
            "355428/355428 [==============================] - 279s 786us/step - loss: 0.6251 - acc: 0.6521 - val_loss: 0.6209 - val_acc: 0.6481\n",
            "Epoch 7/10\n",
            "355428/355428 [==============================] - 279s 784us/step - loss: 0.6238 - acc: 0.6532 - val_loss: 0.6189 - val_acc: 0.6580\n",
            "Epoch 8/10\n",
            "355428/355428 [==============================] - 278s 784us/step - loss: 0.6235 - acc: 0.6541 - val_loss: 0.6240 - val_acc: 0.6440\n",
            "Epoch 9/10\n",
            "355428/355428 [==============================] - 278s 783us/step - loss: 0.6234 - acc: 0.6539 - val_loss: 0.6246 - val_acc: 0.6438\n",
            "Epoch 10/10\n",
            "355428/355428 [==============================] - 278s 783us/step - loss: 0.6235 - acc: 0.6546 - val_loss: 0.6195 - val_acc: 0.6541\n",
            "0.30000000000000004\n",
            "7000\n",
            "Train on 355428 samples, validate on 236952 samples\n",
            "Epoch 1/10\n",
            "355428/355428 [==============================] - 422s 1ms/step - loss: 0.6343 - acc: 0.6464 - val_loss: 0.6309 - val_acc: 0.6425\n",
            "Epoch 2/10\n",
            "355428/355428 [==============================] - 419s 1ms/step - loss: 0.6284 - acc: 0.6497 - val_loss: 0.6226 - val_acc: 0.6468\n",
            "Epoch 3/10\n",
            "355428/355428 [==============================] - 419s 1ms/step - loss: 0.6271 - acc: 0.6510 - val_loss: 0.6289 - val_acc: 0.6459\n",
            "Epoch 4/10\n",
            "355428/355428 [==============================] - 419s 1ms/step - loss: 0.6262 - acc: 0.6510 - val_loss: 0.6252 - val_acc: 0.6461\n",
            "Epoch 5/10\n",
            "355428/355428 [==============================] - 419s 1ms/step - loss: 0.6251 - acc: 0.6521 - val_loss: 0.6237 - val_acc: 0.6538\n",
            "Epoch 6/10\n",
            "355428/355428 [==============================] - 419s 1ms/step - loss: 0.6246 - acc: 0.6524 - val_loss: 0.6279 - val_acc: 0.6481\n",
            "Epoch 7/10\n",
            "355428/355428 [==============================] - 419s 1ms/step - loss: 0.6240 - acc: 0.6533 - val_loss: 0.6242 - val_acc: 0.6530\n",
            "Epoch 8/10\n",
            "355428/355428 [==============================] - 419s 1ms/step - loss: 0.6229 - acc: 0.6537 - val_loss: 0.6186 - val_acc: 0.6569\n",
            "Epoch 9/10\n",
            "355428/355428 [==============================] - 418s 1ms/step - loss: 0.6237 - acc: 0.6536 - val_loss: 0.6216 - val_acc: 0.6521\n",
            "Epoch 10/10\n",
            "355428/355428 [==============================] - 419s 1ms/step - loss: 0.6230 - acc: 0.6544 - val_loss: 0.6219 - val_acc: 0.6500\n",
            "WARNING:tensorflow:Large dropout rate: 0.5 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.5 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "0.5000000000000001\n",
            "4000\n",
            "Train on 355428 samples, validate on 236952 samples\n",
            "Epoch 1/10\n",
            "355428/355428 [==============================] - 167s 469us/step - loss: 0.6348 - acc: 0.6446 - val_loss: 0.6241 - val_acc: 0.6507\n",
            "Epoch 2/10\n",
            "355428/355428 [==============================] - 165s 464us/step - loss: 0.6289 - acc: 0.6485 - val_loss: 0.6245 - val_acc: 0.6488\n",
            "Epoch 3/10\n",
            "355428/355428 [==============================] - 165s 464us/step - loss: 0.6275 - acc: 0.6494 - val_loss: 0.6209 - val_acc: 0.6525\n",
            "Epoch 4/10\n",
            "355428/355428 [==============================] - 165s 464us/step - loss: 0.6269 - acc: 0.6503 - val_loss: 0.6196 - val_acc: 0.6567\n",
            "Epoch 5/10\n",
            "355428/355428 [==============================] - 165s 464us/step - loss: 0.6258 - acc: 0.6511 - val_loss: 0.6193 - val_acc: 0.6565\n",
            "Epoch 6/10\n",
            "355428/355428 [==============================] - 165s 464us/step - loss: 0.6259 - acc: 0.6525 - val_loss: 0.6202 - val_acc: 0.6561\n",
            "Epoch 7/10\n",
            "355428/355428 [==============================] - 165s 464us/step - loss: 0.6258 - acc: 0.6521 - val_loss: 0.6187 - val_acc: 0.6578\n",
            "Epoch 8/10\n",
            "355428/355428 [==============================] - 165s 464us/step - loss: 0.6251 - acc: 0.6529 - val_loss: 0.6194 - val_acc: 0.6578\n",
            "Epoch 9/10\n",
            "355428/355428 [==============================] - 165s 465us/step - loss: 0.6254 - acc: 0.6529 - val_loss: 0.6195 - val_acc: 0.6555\n",
            "Epoch 10/10\n",
            "355428/355428 [==============================] - 166s 466us/step - loss: 0.6251 - acc: 0.6527 - val_loss: 0.6219 - val_acc: 0.6472\n",
            "WARNING:tensorflow:Large dropout rate: 0.5 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.5 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "0.5000000000000001\n",
            "5500\n",
            "Train on 355428 samples, validate on 236952 samples\n",
            "Epoch 1/10\n",
            "355428/355428 [==============================] - 280s 788us/step - loss: 0.6366 - acc: 0.6440 - val_loss: 0.6268 - val_acc: 0.6434\n",
            "Epoch 2/10\n",
            "355428/355428 [==============================] - 278s 781us/step - loss: 0.6306 - acc: 0.6472 - val_loss: 0.6221 - val_acc: 0.6535\n",
            "Epoch 3/10\n",
            "355428/355428 [==============================] - 277s 779us/step - loss: 0.6297 - acc: 0.6489 - val_loss: 0.6242 - val_acc: 0.6461\n",
            "Epoch 4/10\n",
            "355428/355428 [==============================] - 277s 780us/step - loss: 0.6281 - acc: 0.6493 - val_loss: 0.6227 - val_acc: 0.6508\n",
            "Epoch 5/10\n",
            "355428/355428 [==============================] - 279s 784us/step - loss: 0.6272 - acc: 0.6506 - val_loss: 0.6218 - val_acc: 0.6557\n",
            "Epoch 6/10\n",
            "355428/355428 [==============================] - 278s 783us/step - loss: 0.6271 - acc: 0.6509 - val_loss: 0.6220 - val_acc: 0.6528\n",
            "Epoch 7/10\n",
            "355428/355428 [==============================] - 279s 784us/step - loss: 0.6267 - acc: 0.6512 - val_loss: 0.6211 - val_acc: 0.6526\n",
            "Epoch 8/10\n",
            "355428/355428 [==============================] - 278s 783us/step - loss: 0.6268 - acc: 0.6523 - val_loss: 0.6232 - val_acc: 0.6492\n",
            "Epoch 9/10\n",
            "355428/355428 [==============================] - 278s 783us/step - loss: 0.6266 - acc: 0.6514 - val_loss: 0.6225 - val_acc: 0.6560\n",
            "Epoch 10/10\n",
            "355428/355428 [==============================] - 278s 782us/step - loss: 0.6257 - acc: 0.6513 - val_loss: 0.6192 - val_acc: 0.6548\n",
            "WARNING:tensorflow:Large dropout rate: 0.5 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "0.5000000000000001\n",
            "7000\n",
            "Train on 355428 samples, validate on 236952 samples\n",
            "Epoch 1/10\n",
            "355428/355428 [==============================] - 417s 1ms/step - loss: 0.6398 - acc: 0.6424 - val_loss: 0.6254 - val_acc: 0.6439\n",
            "Epoch 2/10\n",
            "355428/355428 [==============================] - 412s 1ms/step - loss: 0.6347 - acc: 0.6460 - val_loss: 0.6236 - val_acc: 0.6530\n",
            "Epoch 3/10\n",
            "355428/355428 [==============================] - 412s 1ms/step - loss: 0.6335 - acc: 0.6468 - val_loss: 0.6236 - val_acc: 0.6490\n",
            "Epoch 4/10\n",
            " 31648/355428 [=>............................] - ETA: 5:59 - loss: 0.6349 - acc: 0.6452"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-a608ab355789>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     hist_3 = model_3.fit(X_train, y_train,\n\u001b[1;32m     21\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m               validation_data=(X_test, y_test))\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK3sjLNRs5G5",
        "colab_type": "code",
        "outputId": "051a8ea2-2227-4672-ee14-0205e6ea9c4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#conclusion: 0.5 is way too high, 0.3 not  rly good eiher.."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.1, 0.2, 0.3, 0.4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPS0WW4P6dWQ",
        "colab_type": "code",
        "outputId": "5a38d4a6-f531-4689-8351-d9f840e261f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        }
      },
      "source": [
        "from keras import regularizers\n",
        "\n",
        "num_hidden_units = 7000\n",
        "d1 =  0.2\n",
        "d2 = 0.1\n",
        "# models = []\n",
        "model_3 = Sequential([\n",
        "    Dense(num_hidden_units, activation='relu',input_shape=(33,)),\n",
        "    Dropout(d1),\n",
        "    Dense(num_hidden_units, activation='relu'),\n",
        "    Dropout(d2),\n",
        "    Dense(num_hidden_units, activation='relu'),\n",
        "    Dense(1, activation='sigmoid'),\n",
        "])\n",
        "print(d1)\n",
        "print(num_hidden_units)\n",
        "model_3.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "hist_3 = model_3.fit(X_train, y_train,\n",
        "          batch_size=32, epochs=10,\n",
        "          validation_data=(X_test, y_test))\n",
        "models.append(model_3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2\n",
            "7000\n",
            "Train on 473904 samples, validate on 118476 samples\n",
            "Epoch 1/10\n",
            "473904/473904 [==============================] - 537s 1ms/step - loss: 0.6284 - acc: 0.6494 - val_loss: 0.6218 - val_acc: 0.6549\n",
            "Epoch 2/10\n",
            "473904/473904 [==============================] - 534s 1ms/step - loss: 0.6236 - acc: 0.6533 - val_loss: 0.6200 - val_acc: 0.6542\n",
            "Epoch 3/10\n",
            "473904/473904 [==============================] - 534s 1ms/step - loss: 0.6219 - acc: 0.6545 - val_loss: 0.6230 - val_acc: 0.6528\n",
            "Epoch 4/10\n",
            "473904/473904 [==============================] - 535s 1ms/step - loss: 0.6213 - acc: 0.6549 - val_loss: 0.6187 - val_acc: 0.6581\n",
            "Epoch 5/10\n",
            "473904/473904 [==============================] - 534s 1ms/step - loss: 0.6208 - acc: 0.6559 - val_loss: 0.6215 - val_acc: 0.6495\n",
            "Epoch 6/10\n",
            "473904/473904 [==============================] - 535s 1ms/step - loss: 0.6200 - acc: 0.6556 - val_loss: 0.6211 - val_acc: 0.6563\n",
            "Epoch 7/10\n",
            "473904/473904 [==============================] - 534s 1ms/step - loss: 0.6197 - acc: 0.6564 - val_loss: 0.6185 - val_acc: 0.6581\n",
            "Epoch 8/10\n",
            "473904/473904 [==============================] - 534s 1ms/step - loss: 0.6199 - acc: 0.6570 - val_loss: 0.6172 - val_acc: 0.6568\n",
            "Epoch 9/10\n",
            "267680/473904 [===============>..............] - ETA: 3:48 - loss: 0.6193 - acc: 0.6571"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-c3ff3ed1eae7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m hist_3 = model_3.fit(X_train, y_train,\n\u001b[1;32m     21\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m           validation_data=(X_test, y_test))\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX1LTUZt6rGm",
        "colab_type": "code",
        "outputId": "91b5690e-4cf6-4cc4-ede3-7a1042b0c0d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        }
      },
      "source": [
        "#half the hideen units in the subsequent layers\n",
        "num_hidden_units = 7000\n",
        "d1 =  0.2\n",
        "d2 = 0.1\n",
        "# models = []\n",
        "model_3 = Sequential([\n",
        "    Dense(num_hidden_units, activation='relu',input_shape=(33,)),\n",
        "    Dropout(d1),\n",
        "    Dense(int(num_hidden_units/2), activation='relu'),\n",
        "    Dropout(d2),\n",
        "    Dense(int(num_hidden_units/2), activation='relu'),\n",
        "    Dense(1, activation='sigmoid'),\n",
        "])\n",
        "print(d1)\n",
        "print(num_hidden_units)\n",
        "model_3.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "hist_3 = model_3.fit(X_train, y_train,\n",
        "          batch_size=32, epochs=10,\n",
        "          validation_data=(X_test, y_test))\n",
        "models.append(model_3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2\n",
            "7000\n",
            "Train on 473904 samples, validate on 118476 samples\n",
            "Epoch 1/10\n",
            "473904/473904 [==============================] - 232s 490us/step - loss: 0.6267 - acc: 0.6500 - val_loss: 0.6243 - val_acc: 0.6529\n",
            "Epoch 2/10\n",
            "473904/473904 [==============================] - 230s 486us/step - loss: 0.6229 - acc: 0.6533 - val_loss: 0.6195 - val_acc: 0.6556\n",
            "Epoch 3/10\n",
            "473904/473904 [==============================] - 230s 486us/step - loss: 0.6217 - acc: 0.6544 - val_loss: 0.6244 - val_acc: 0.6524\n",
            "Epoch 4/10\n",
            "473904/473904 [==============================] - 231s 487us/step - loss: 0.6210 - acc: 0.6555 - val_loss: 0.6197 - val_acc: 0.6514\n",
            "Epoch 5/10\n",
            "473904/473904 [==============================] - 230s 485us/step - loss: 0.6206 - acc: 0.6554 - val_loss: 0.6190 - val_acc: 0.6574\n",
            "Epoch 6/10\n",
            "473904/473904 [==============================] - 230s 485us/step - loss: 0.6196 - acc: 0.6554 - val_loss: 0.6191 - val_acc: 0.6578\n",
            "Epoch 7/10\n",
            "473904/473904 [==============================] - 230s 486us/step - loss: 0.6195 - acc: 0.6561 - val_loss: 0.6209 - val_acc: 0.6570\n",
            "Epoch 8/10\n",
            "473904/473904 [==============================] - 231s 486us/step - loss: 0.6189 - acc: 0.6563 - val_loss: 0.6186 - val_acc: 0.6549\n",
            "Epoch 9/10\n",
            "120512/473904 [======>.......................] - ETA: 2:47 - loss: 0.6186 - acc: 0.6568"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-25a2190c6d57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m hist_3 = model_3.fit(X_train, y_train,\n\u001b[1;32m     19\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m           validation_data=(X_test, y_test))\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4hP8YDN7cMn",
        "colab_type": "code",
        "outputId": "9307d9e8-8937-4a42-c8b3-a2ff0730616e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "source": [
        "from keras import regularizers\n",
        "from keras.layers import BatchNormalization\n",
        "num_hidden_units = 3500\n",
        "d1 =  0.2\n",
        "d2 = 0.1\n",
        "# models = []\n",
        "model_3 = Sequential([\n",
        "    Dense(num_hidden_units, activation='relu',input_shape=(33,)),\n",
        "    Dropout(d1),\n",
        "    Dense(num_hidden_units, activation='relu'),\n",
        "    Dropout(d2),\n",
        "    Dense(num_hidden_units, activation='relu'),\n",
        "    Dropout(d2),\n",
        "    Dense(num_hidden_units, activation='relu'),\n",
        "    Dense(1, activation='sigmoid'),\n",
        "])\n",
        "print(d1)\n",
        "print(num_hidden_units)\n",
        "model_3.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "hist_3 = model_3.fit(X_train, y_train,\n",
        "          batch_size=32, epochs=10,\n",
        "          validation_data=(X_test, y_test))\n",
        "models.append(model_3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2\n",
            "3500\n",
            "Train on 473904 samples, validate on 118476 samples\n",
            "Epoch 1/10\n",
            " 35872/473904 [=>............................] - ETA: 3:51 - loss: 0.6424 - acc: 0.6455"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-0876076c716d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m hist_3 = model_3.fit(X_train, y_train,\n\u001b[1;32m     23\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m           validation_data=(X_test, y_test))\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFMx42jkWUB7",
        "colab_type": "code",
        "outputId": "80938aab-da81-4316-845c-cbc6c75b786c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        }
      },
      "source": [
        "from keras import regularizers\n",
        "\n",
        "num_hidden_units = 3500\n",
        "d1 =  0.2\n",
        "d2 = 0.1\n",
        "model_3 = Sequential([\n",
        "    Dense(num_hidden_units, activation='relu',input_shape=(33,)),\n",
        "    Dropout(d1),\n",
        "    BatchNormalization(),\n",
        "    Dense(num_hidden_units, activation='relu'),\n",
        "    Dropout(d2),\n",
        "    BatchNormalization(),\n",
        "    Dense(num_hidden_units, activation='relu'),\n",
        "    Dropout(d2),\n",
        "    BatchNormalization(),\n",
        "    Dense(num_hidden_units, activation='relu'),\n",
        "    Dense(1, activation='sigmoid'),\n",
        "])\n",
        "model_3.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "hist_3 = model_3.fit(X_train, y_train,\n",
        "          batch_size=32, epochs=10,\n",
        "          validation_data=(X_test, y_test))\n",
        "models.append(model_3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 473904 samples, validate on 118476 samples\n",
            "Epoch 1/10\n",
            "473904/473904 [==============================] - 277s 584us/step - loss: 5.7535 - acc: 0.6430 - val_loss: 5.7702 - val_acc: 0.6420\n",
            "Epoch 2/10\n",
            "473904/473904 [==============================] - 274s 577us/step - loss: 5.7493 - acc: 0.6433 - val_loss: 5.7702 - val_acc: 0.6420\n",
            "Epoch 3/10\n",
            "137376/473904 [=======>......................] - ETA: 3:08 - loss: 5.7656 - acc: 0.6423"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-3947318bab39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m hist_3 = model_3.fit(X_train, y_train,\n\u001b[1;32m     24\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m           validation_data=(X_test, y_test))\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSzivrd47fjq",
        "colab_type": "code",
        "outputId": "81292462-46c8-4cdc-bf01-65e60609d93f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        }
      },
      "source": [
        "\n",
        "num_hidden_units = 3500\n",
        "d1 =  0.2\n",
        "d2 = 0.1\n",
        "# models = []\n",
        "model_3 = Sequential([\n",
        "    Dense(num_hidden_units, activation='relu',input_shape=(33,)),\n",
        "    Dropout(d1),\n",
        "    Dense(num_hidden_units, activation='relu',kernel_regularizer=regularizers.l2(0.01)),\n",
        "    Dropout(d2),\n",
        "    Dense(num_hidden_units, activation='relu',kernel_regularizer=regularizers.l2(0.01)),\n",
        "    Dropout(d2),\n",
        "    Dense(num_hidden_units, activation='relu',kernel_regularizer=regularizers.l2(0.01)),\n",
        "    Dense(1, activation='sigmoid'),\n",
        "])\n",
        "print(d1)\n",
        "print(num_hidden_units)\n",
        "model_3.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "hist_3 = model_3.fit(X_train, y_train,\n",
        "          batch_size=32, epochs=10,\n",
        "          validation_data=(X_test, y_test))\n",
        "models.append(model_3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2\n",
            "3500\n",
            "Train on 473904 samples, validate on 118476 samples\n",
            "Epoch 1/10\n",
            "473904/473904 [==============================] - 294s 621us/step - loss: 0.7157 - acc: 0.6433 - val_loss: 0.6525 - val_acc: 0.6420\n",
            "Epoch 2/10\n",
            "473904/473904 [==============================] - 292s 616us/step - loss: 0.6517 - acc: 0.6433 - val_loss: 0.6524 - val_acc: 0.6420\n",
            "Epoch 3/10\n",
            "473904/473904 [==============================] - 292s 616us/step - loss: 0.6517 - acc: 0.6433 - val_loss: 0.6523 - val_acc: 0.6420\n",
            "Epoch 4/10\n",
            "473904/473904 [==============================] - 292s 616us/step - loss: 0.6516 - acc: 0.6433 - val_loss: 0.6523 - val_acc: 0.6420\n",
            "Epoch 5/10\n",
            "155552/473904 [========>.....................] - ETA: 3:09 - loss: 0.6520 - acc: 0.6426"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-69e720b4acfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m hist_3 = model_3.fit(X_train, y_train,\n\u001b[1;32m     22\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m           validation_data=(X_test, y_test))\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3jd6eI7mm_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Split test and train data\n",
        "# df_train = train_df.fillna(train_df.median())\n",
        "\n",
        "\n",
        "# df_train['opened_position_qty '].fillna((df_train['transacted_qty']), inplace=True)\n",
        "\n",
        "# df_train['closed_position_qty'].fillna((0), inplace=True)\n",
        "df_train = train_df.fillna(train_df.median())\n",
        "\n",
        "# df_train['closed_position_qty'].fillna((df_train['transacted_qty'] / 2), inplace=True)\n",
        "\n",
        "\n",
        "df_train['diff'] = (df_train['last_price'] - df_train['mid'])\n",
        "df_train['avg_bid'] = (df_train['bid1'] * df_train['bid1vol'] + df_train['bid2'] * df_train['bid2vol'] + df_train['bid3'] * df_train['bid3vol'] + df_train['bid4'] * df_train['bid4vol'] + df_train['bid5'] * df_train['bid5vol']) / (df_train['bid1vol'] + df_train['bid2vol'] + df_train['bid3vol'] + df_train['bid4vol'] + df_train['bid5vol'])\n",
        "df_train['avg_ask'] = (df_train['ask1'] * df_train['ask1vol'] + df_train['ask2'] * df_train['ask2vol'] + df_train['ask3'] * df_train['ask3vol'] + df_train['ask4'] * df_train['ask4vol'] + df_train['ask5'] * df_train['ask5vol']) / (df_train['ask1vol'] + df_train['ask2vol'] + df_train['ask3vol'] + df_train['ask4vol'] + df_train['ask5vol'])\n",
        "df_train['diff_avg_bid'] = (df_train['mid'] - df_train['avg_bid'])\n",
        "df_train['diff_avg_ask'] = (df_train['mid'] - df_train['avg_ask'])\n",
        "#df_train['diff_avg_bid_ask'] = (df_train['avg_ask'] - df_train['avg_bid'])\n",
        "#X = df_train.drop('y', axis=1)\n",
        "X = df_train.drop(['id', 'y'], axis=1)\n",
        "eff_spread = []\n",
        "\n",
        "for index, row in df_train.iterrows():\n",
        "    \n",
        "    #check buyer initiated\n",
        "    if row['diff_avg_bid'] > row['diff_avg_ask']:\n",
        "        ind = 1\n",
        "    else:\n",
        "        ind = -1\n",
        "        \n",
        "    eff_spread.append(ind * (row['diff']))\n",
        "    \n",
        "\n",
        "df_train['effective_spread'] = eff_spread\n",
        "\n",
        "y = df_train['y']\n",
        "\n",
        "X = df_train.drop(['id', 'y'], axis=1)\n",
        "\n",
        "normalized_X=(X-X.mean())/X.std()\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_X, y, test_size=0.2, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QILAiE4-_3he",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "X = df_train.drop(['id', 'y'], axis=1)\n",
        "\n",
        "normalized_X=(X-X.mean())/X.std()\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_X, y, test_size=0.2, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-k1QjQ3AGAQ",
        "colab_type": "code",
        "outputId": "7ff3c046-4e89-40c6-b6fd-87448ad4ed32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "X_train.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['last_price', 'mid', 'opened_position_qty ', 'closed_position_qty',\n",
              "       'transacted_qty', 'd_open_interest', 'bid1', 'bid2', 'bid3', 'bid4',\n",
              "       'bid5', 'ask1', 'ask2', 'ask3', 'ask4', 'ask5', 'bid1vol', 'bid2vol',\n",
              "       'bid3vol', 'bid4vol', 'bid5vol', 'ask1vol', 'ask2vol', 'ask3vol',\n",
              "       'ask4vol', 'ask5vol', 'diff', 'avg_bid', 'avg_ask', 'diff_avg_bid',\n",
              "       'diff_avg_ask', 'effective_spread'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdrJ_Gpu6_pH",
        "colab_type": "code",
        "outputId": "d7dedd09-c9ed-4f11-ce12-91d14dc3e565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import lightgbm as lgb\n",
        "d_train = lgb.Dataset(X_train, label=y_train)\n",
        "param = {\"max_depth\": 5, \"learning_rate\": 0.1, \"num_leaves\": 900, \"n_estimators\": 100}\n",
        "model2 = lgb.train(params=param,train_set=d_train)\n",
        "# print(‘Plot feature importances…’)\n",
        "ax = lgb.plot_importance(model2, max_num_features=10)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb0AAAEWCAYAAADy9UlpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyMC6vyy__KI",
        "colab_type": "code",
        "outputId": "badf6f02-6138-4353-f9d4-392c400db427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(X_train.columns)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['last_price', 'mid', 'opened_position_qty ', 'closed_position_qty',\n",
            "       'transacted_qty', 'd_open_interest', 'bid1', 'bid2', 'bid3', 'bid4',\n",
            "       'bid5', 'ask1', 'ask2', 'ask3', 'ask4', 'ask5', 'bid1vol', 'bid2vol',\n",
            "       'bid3vol', 'bid4vol', 'bid5vol', 'ask1vol', 'ask2vol', 'ask3vol',\n",
            "       'ask4vol', 'ask5vol', 'diff', 'avg_bid', 'avg_ask', 'diff_avg_bid',\n",
            "       'diff_avg_ask', 'diff_avg_bid_ask', 'effective_spread'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHxWCOQl7Ffq",
        "colab_type": "code",
        "outputId": "50e26940-1586-4eca-8ce4-c76cead6bdcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import lightgbm as lgb\n",
        "d_train = lgb.Dataset(X_train, label=y_train)\n",
        "print(X_train.columns)\n",
        "param = {\"max_depth\": 5, \"learning_rate\": 0.1, \"num_leaves\": 900, \"n_estimators\": 100}\n",
        "model2 = lgb.train(params=param,train_set=d_train)\n",
        "# print(‘Plot feature importances…’)\n",
        "plt.figure(figsize=(100,25))\n",
        "ax = lgb.plot_importance(model2, max_num_features=34)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['last_price', 'mid', 'opened_position_qty ', 'closed_position_qty',\n",
            "       'transacted_qty', 'd_open_interest', 'bid1', 'bid2', 'bid3', 'bid4',\n",
            "       'bid5', 'ask1', 'ask2', 'ask3', 'ask4', 'ask5', 'bid1vol', 'bid2vol',\n",
            "       'bid3vol', 'bid4vol', 'bid5vol', 'ask1vol', 'ask2vol', 'ask3vol',\n",
            "       'ask4vol', 'ask5vol', 'diff', 'avg_bid', 'avg_ask', 'diff_avg_bid',\n",
            "       'diff_avg_ask', 'effective_spread'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 7200x1800 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd4AAAEWCAYAAADIJfYaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EQB1rojBZ68",
        "colab_type": "code",
        "outputId": "3e4ac0dd-6601-4bec-d979-e35ea665d05f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        }
      },
      "source": [
        "\n",
        "lgb.create_tree_digraph(model2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f965b97a908>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"10330pt\" height=\"585pt\"\n viewBox=\"0.00 0.00 10329.59 585.44\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 581.4407)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-581.4407 10325.5914,-581.4407 10325.5914,4 -4,4\"/>\n<!-- split0 -->\n<g id=\"node1\" class=\"node\">\n<title>split0</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"5404.3209\" cy=\"-550.5706\" rx=\"150.7276\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"5404.3209\" y=\"-554.3706\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_feature_name: ask1vol</text>\n<text text-anchor=\"middle\" x=\"5404.3209\" y=\"-539.3706\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">threshold: &#45;0.5299802098329899</text>\n</g>\n<!-- split2 -->\n<g id=\"node2\" class=\"node\">\n<title>split2</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"3638.3209\" cy=\"-445.8305\" rx=\"165.426\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"3638.3209\" y=\"-449.6305\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_feature_name: diff</text>\n<text text-anchor=\"middle\" x=\"3638.3209\" y=\"-434.6305\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">threshold: 1.0000000180025095e&#45;35</text>\n</g>\n<!-- split0&#45;&gt;split2 -->\n<g id=\"edge31\" class=\"edge\">\n<title>split0&#45;&gt;split2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M5261.2976,-542.088C4937.2688,-522.8701 4148.6485,-476.0977 3804.0521,-455.6599\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3804.1771,-452.1613 3793.9874,-455.063 3803.7626,-459.149 3804.1771,-452.1613\"/>\n<text text-anchor=\"middle\" x=\"4635.8209\" y=\"-494.5006\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;=</text>\n</g>\n<!-- split1 -->\n<g id=\"node33\" class=\"node\">\n<title>split1</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"6315.3209\" cy=\"-445.8305\" rx=\"155.627\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"6315.3209\" y=\"-449.6305\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_feature_name: diff</text>\n<text text-anchor=\"middle\" x=\"6315.3209\" y=\"-434.6305\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">threshold: &#45;0.47271100918774983</text>\n</g>\n<!-- split0&#45;&gt;split1 -->\n<g id=\"edge62\" class=\"edge\">\n<title>split0&#45;&gt;split1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M5530.9915,-536.007C5700.4074,-516.5288 5999.7725,-482.11 6175.5839,-461.8965\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"6176.1465,-465.3549 6185.6812,-460.7355 6175.3468,-458.4007 6176.1465,-465.3549\"/>\n<text text-anchor=\"middle\" x=\"5919.8209\" y=\"-494.5006\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;</text>\n</g>\n<!-- split7 -->\n<g id=\"node3\" class=\"node\">\n<title>split7</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1863.3209\" cy=\"-341.0904\" rx=\"149.8133\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"1863.3209\" y=\"-344.8904\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_feature_name: bid1vol</text>\n<text text-anchor=\"middle\" x=\"1863.3209\" y=\"-329.8904\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">threshold: &#45;0.5461919001919112</text>\n</g>\n<!-- split2&#45;&gt;split7 -->\n<g id=\"edge15\" class=\"edge\">\n<title>split2&#45;&gt;split7</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3482.745,-436.6502C3145.5678,-416.7539 2350.9086,-369.8622 2016.1927,-350.1111\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2016.1276,-346.6013 2005.9387,-349.5061 2015.7152,-353.5891 2016.1276,-346.6013\"/>\n<text text-anchor=\"middle\" x=\"2865.8209\" y=\"-389.7605\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;=</text>\n</g>\n<!-- split8 -->\n<g id=\"node18\" class=\"node\">\n<title>split8</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"3638.3209\" cy=\"-341.0904\" rx=\"149.8133\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"3638.3209\" y=\"-344.8904\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_feature_name: bid1vol</text>\n<text text-anchor=\"middle\" x=\"3638.3209\" y=\"-329.8904\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">threshold: &#45;0.3119674843097728</text>\n</g>\n<!-- split2&#45;&gt;split8 -->\n<g id=\"edge30\" class=\"edge\">\n<title>split2&#45;&gt;split8</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3638.3209,-418.8573C3638.3209,-406.5179 3638.3209,-391.6964 3638.3209,-378.3175\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3641.8209,-377.9721 3638.3209,-367.9722 3634.8209,-377.9722 3641.8209,-377.9721\"/>\n<text text-anchor=\"middle\" x=\"3642.8209\" y=\"-389.7605\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;</text>\n</g>\n<!-- split24 -->\n<g id=\"node4\" class=\"node\">\n<title>split24</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"964.3209\" cy=\"-236.3503\" rx=\"150.7276\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"964.3209\" y=\"-240.1503\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_feature_name: diff_avg_ask</text>\n<text text-anchor=\"middle\" x=\"964.3209\" y=\"-225.1503\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">threshold: &#45;1.3784667853212484</text>\n</g>\n<!-- split7&#45;&gt;split24 -->\n<g id=\"edge7\" class=\"edge\">\n<title>split7&#45;&gt;split24</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1737.3722,-326.4165C1569.5288,-306.8615 1273.6502,-272.3894 1100.6913,-252.2384\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1100.8413,-248.7323 1090.5034,-251.0515 1100.0311,-255.6853 1100.8413,-248.7323\"/>\n<text text-anchor=\"middle\" x=\"1476.8209\" y=\"-285.0203\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;=</text>\n</g>\n<!-- split16 -->\n<g id=\"node11\" class=\"node\">\n<title>split16</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1863.3209\" cy=\"-236.3503\" rx=\"150.7276\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"1863.3209\" y=\"-240.1503\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_feature_name: diff_avg_bid</text>\n<text text-anchor=\"middle\" x=\"1863.3209\" y=\"-225.1503\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">threshold: &#45;0.5601406623710002</text>\n</g>\n<!-- split7&#45;&gt;split16 -->\n<g id=\"edge14\" class=\"edge\">\n<title>split7&#45;&gt;split16</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1863.3209,-314.1172C1863.3209,-301.7778 1863.3209,-286.9563 1863.3209,-273.5774\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1866.8209,-273.232 1863.3209,-263.2321 1859.8209,-273.2321 1866.8209,-273.232\"/>\n<text text-anchor=\"middle\" x=\"1867.8209\" y=\"-285.0203\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;</text>\n</g>\n<!-- split30 -->\n<g id=\"node5\" class=\"node\">\n<title>split30</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"472.3209\" cy=\"-131.6102\" rx=\"147.5709\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"472.3209\" y=\"-135.4102\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_feature_name: diff_avg_bid</text>\n<text text-anchor=\"middle\" x=\"472.3209\" y=\"-120.4102\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">threshold: 0.7640335991435561</text>\n</g>\n<!-- split24&#45;&gt;split30 -->\n<g id=\"edge3\" class=\"edge\">\n<title>split24&#45;&gt;split30</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M867.4112,-215.7195C784.2015,-198.0053 664.4518,-172.5122 578.6302,-154.242\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"579.1097,-150.7657 568.6001,-152.1067 577.6521,-157.6123 579.1097,-150.7657\"/>\n<text text-anchor=\"middle\" x=\"756.8209\" y=\"-180.2802\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;=</text>\n</g>\n<!-- split26 -->\n<g id=\"node8\" class=\"node\">\n<title>split26</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"964.3209\" cy=\"-131.6102\" rx=\"155.627\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"964.3209\" y=\"-135.4102\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_feature_name: diff</text>\n<text text-anchor=\"middle\" x=\"964.3209\" y=\"-120.4102\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">threshold: &#45;0.47271100918774983</text>\n</g>\n<!-- split24&#45;&gt;split26 -->\n<g id=\"edge6\" class=\"edge\">\n<title>split24&#45;&gt;split26</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M964.3209,-209.3771C964.3209,-197.0377 964.3209,-182.2162 964.3209,-168.8373\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"967.8209,-168.4919 964.3209,-158.4919 960.8209,-168.492 967.8209,-168.4919\"/>\n<text text-anchor=\"middle\" x=\"968.8209\" y=\"-180.2802\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;</text>\n</g>\n<!-- leaf0 -->\n<g id=\"node6\" class=\"node\">\n<title>leaf0</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"151.3209\" cy=\"-26.8701\" rx=\"151.1419\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"151.3209\" y=\"-30.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_index: 0</text>\n<text text-anchor=\"middle\" x=\"151.3209\" y=\"-15.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_value: 0.3689085609361383</text>\n</g>\n<!-- split30&#45;&gt;leaf0 -->\n<g id=\"edge1\" class=\"edge\">\n<title>split30&#45;&gt;leaf0</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M400.2822,-108.1044C350.7906,-91.9557 284.9791,-70.4818 233.4505,-53.6684\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"234.2662,-50.253 223.6737,-50.4783 232.0947,-56.9077 234.2662,-50.253\"/>\n<text text-anchor=\"middle\" x=\"339.8209\" y=\"-75.5401\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;=</text>\n</g>\n<!-- leaf31 -->\n<g id=\"node7\" class=\"node\">\n<title>leaf31</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"472.3209\" cy=\"-26.8701\" rx=\"151.1419\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"472.3209\" y=\"-30.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_index: 31</text>\n<text text-anchor=\"middle\" x=\"472.3209\" y=\"-15.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_value: 0.3588374336078222</text>\n</g>\n<!-- split30&#45;&gt;leaf31 -->\n<g id=\"edge2\" class=\"edge\">\n<title>split30&#45;&gt;leaf31</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M472.3209,-104.637C472.3209,-92.2976 472.3209,-77.4761 472.3209,-64.0972\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"475.8209,-63.7518 472.3209,-53.7518 468.8209,-63.7519 475.8209,-63.7518\"/>\n<text text-anchor=\"middle\" x=\"476.8209\" y=\"-75.5401\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;</text>\n</g>\n<!-- leaf25 -->\n<g id=\"node9\" class=\"node\">\n<title>leaf25</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"793.3209\" cy=\"-26.8701\" rx=\"151.1419\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"793.3209\" y=\"-30.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_index: 25</text>\n<text text-anchor=\"middle\" x=\"793.3209\" y=\"-15.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_value: 0.3530020237722407</text>\n</g>\n<!-- split26&#45;&gt;leaf25 -->\n<g id=\"edge4\" class=\"edge\">\n<title>split26&#45;&gt;leaf25</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M922.0512,-105.7194C898.5178,-91.3048 869.0549,-73.2583 844.2565,-58.0689\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"846.0525,-55.0647 835.6969,-52.826 842.3963,-61.0339 846.0525,-55.0647\"/>\n<text text-anchor=\"middle\" x=\"897.8209\" y=\"-75.5401\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;=</text>\n</g>\n<!-- leaf27 -->\n<g id=\"node10\" class=\"node\">\n<title>leaf27</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1114.3209\" cy=\"-26.8701\" rx=\"151.1419\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"1114.3209\" y=\"-30.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_index: 27</text>\n<text text-anchor=\"middle\" x=\"1114.3209\" y=\"-15.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_value: 0.3604774834216134</text>\n</g>\n<!-- split26&#45;&gt;leaf27 -->\n<g id=\"edge5\" class=\"edge\">\n<title>split26&#45;&gt;leaf27</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1001.7853,-105.45C1022.0093,-91.3282 1047.1396,-73.7806 1068.5189,-58.8521\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1070.619,-61.6545 1076.8142,-53.0597 1066.6114,-55.9152 1070.619,-61.6545\"/>\n<text text-anchor=\"middle\" x=\"1052.8209\" y=\"-75.5401\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;</text>\n</g>\n<!-- split25 -->\n<g id=\"node12\" class=\"node\">\n<title>split25</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1771.3209\" cy=\"-131.6102\" rx=\"146.2423\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"1771.3209\" y=\"-135.4102\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_feature_name: diff_avg_ask</text>\n<text text-anchor=\"middle\" x=\"1771.3209\" y=\"-120.4102\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">threshold: &#45;1.412032174945786</text>\n</g>\n<!-- split16&#45;&gt;split25 -->\n<g id=\"edge10\" class=\"edge\">\n<title>split16&#45;&gt;split25</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1839.8673,-209.6489C1828.1885,-196.3528 1813.9336,-180.1239 1801.4542,-165.9164\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1803.9606,-163.4662 1794.7316,-158.2628 1798.7013,-168.0858 1803.9606,-163.4662\"/>\n<text text-anchor=\"middle\" x=\"1831.8209\" y=\"-180.2802\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;=</text>\n</g>\n<!-- split28 -->\n<g id=\"node15\" class=\"node\">\n<title>split28</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"2097.3209\" cy=\"-131.6102\" rx=\"147.5709\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"2097.3209\" y=\"-135.4102\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_feature_name: diff_avg_bid</text>\n<text text-anchor=\"middle\" x=\"2097.3209\" y=\"-120.4102\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">threshold: 0.7967127927073909</text>\n</g>\n<!-- split16&#45;&gt;split28 -->\n<g id=\"edge13\" class=\"edge\">\n<title>split16&#45;&gt;split28</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1919.3697,-211.2624C1953.2537,-196.0957 1996.6003,-176.6934 2032.0286,-160.8355\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2033.6269,-163.9548 2041.3243,-156.6746 2030.767,-157.5656 2033.6269,-163.9548\"/>\n<text text-anchor=\"middle\" x=\"1999.8209\" y=\"-180.2802\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;</text>\n</g>\n<!-- leaf8 -->\n<g id=\"node13\" class=\"node\">\n<title>leaf8</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1440.3209\" cy=\"-26.8701\" rx=\"156.0415\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"1440.3209\" y=\"-30.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_index: 8</text>\n<text text-anchor=\"middle\" x=\"1440.3209\" y=\"-15.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_value: 0.38137377155928087</text>\n</g>\n<!-- split25&#45;&gt;leaf8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>split25&#45;&gt;leaf8</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1697.8612,-108.3649C1646.6711,-92.1666 1578.2554,-70.5174 1524.8054,-53.6039\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1525.5968,-50.1834 1515.0067,-50.5033 1523.4849,-56.8572 1525.5968,-50.1834\"/>\n<text text-anchor=\"middle\" x=\"1634.8209\" y=\"-75.5401\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;=</text>\n</g>\n<!-- leaf26 -->\n<g id=\"node14\" class=\"node\">\n<title>leaf26</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1771.3209\" cy=\"-26.8701\" rx=\"156.0415\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"1771.3209\" y=\"-30.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_index: 26</text>\n<text text-anchor=\"middle\" x=\"1771.3209\" y=\"-15.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_value: 0.36924343605674437</text>\n</g>\n<!-- split25&#45;&gt;leaf26 -->\n<g id=\"edge9\" class=\"edge\">\n<title>split25&#45;&gt;leaf26</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1771.3209,-104.637C1771.3209,-92.2976 1771.3209,-77.4761 1771.3209,-64.0972\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1774.8209,-63.7518 1771.3209,-53.7518 1767.8209,-63.7519 1774.8209,-63.7518\"/>\n<text text-anchor=\"middle\" x=\"1775.8209\" y=\"-75.5401\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;</text>\n</g>\n<!-- leaf17 -->\n<g id=\"node16\" class=\"node\">\n<title>leaf17</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"2097.3209\" cy=\"-26.8701\" rx=\"151.1419\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"2097.3209\" y=\"-30.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_index: 17</text>\n<text text-anchor=\"middle\" x=\"2097.3209\" y=\"-15.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_value: 0.3647308633141261</text>\n</g>\n<!-- split28&#45;&gt;leaf17 -->\n<g id=\"edge11\" class=\"edge\">\n<title>split28&#45;&gt;leaf17</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2097.3209,-104.637C2097.3209,-92.2976 2097.3209,-77.4761 2097.3209,-64.0972\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2100.8209,-63.7518 2097.3209,-53.7518 2093.8209,-63.7519 2100.8209,-63.7518\"/>\n<text text-anchor=\"middle\" x=\"2105.8209\" y=\"-75.5401\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;=</text>\n</g>\n<!-- leaf29 -->\n<g id=\"node17\" class=\"node\">\n<title>leaf29</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"2418.3209\" cy=\"-26.8701\" rx=\"151.1419\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"2418.3209\" y=\"-30.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_index: 29</text>\n<text text-anchor=\"middle\" x=\"2418.3209\" y=\"-15.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_value: 0.3597284648491862</text>\n</g>\n<!-- split28&#45;&gt;leaf29 -->\n<g id=\"edge12\" class=\"edge\">\n<title>split28&#45;&gt;leaf29</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2169.3595,-108.1044C2218.8511,-91.9557 2284.6626,-70.4818 2336.1912,-53.6684\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2337.547,-56.9077 2345.968,-50.4783 2335.3755,-50.253 2337.547,-56.9077\"/>\n<text text-anchor=\"middle\" x=\"2281.8209\" y=\"-75.5401\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;</text>\n</g>\n<!-- split13 -->\n<g id=\"node19\" class=\"node\">\n<title>split13</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"3431.3209\" cy=\"-236.3503\" rx=\"150.7276\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"3431.3209\" y=\"-240.1503\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_feature_name: diff_avg_ask</text>\n<text text-anchor=\"middle\" x=\"3431.3209\" y=\"-225.1503\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">threshold: &#45;0.8909694599047998</text>\n</g>\n<!-- split8&#45;&gt;split13 -->\n<g id=\"edge22\" class=\"edge\">\n<title>split8&#45;&gt;split13</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3588.2119,-315.7357C3558.8082,-300.8577 3521.4875,-281.9738 3490.6233,-266.3568\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3492.1888,-263.2264 3481.6858,-261.8345 3489.0284,-269.4724 3492.1888,-263.2264\"/>\n<text text-anchor=\"middle\" x=\"3555.8209\" y=\"-285.0203\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;=</text>\n</g>\n<!-- split18 -->\n<g id=\"node26\" class=\"node\">\n<title>split18</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"4202.3209\" cy=\"-236.3503\" rx=\"147.5709\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"4202.3209\" y=\"-240.1503\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_feature_name: diff</text>\n<text text-anchor=\"middle\" x=\"4202.3209\" y=\"-225.1503\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">threshold: 1.8801675494300243</text>\n</g>\n<!-- split8&#45;&gt;split18 -->\n<g id=\"edge29\" class=\"edge\">\n<title>split8&#45;&gt;split18</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3742.7536,-321.6963C3840.9044,-303.4687 3987.4389,-276.2559 4088.5279,-257.4827\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"4089.2791,-260.9031 4098.472,-255.636 4088.001,-254.0208 4089.2791,-260.9031\"/>\n<text text-anchor=\"middle\" x=\"3958.8209\" y=\"-285.0203\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;</text>\n</g>\n<!-- split27 -->\n<g id=\"node20\" class=\"node\">\n<title>split27</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"3065.3209\" cy=\"-131.6102\" rx=\"136.4432\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"3065.3209\" y=\"-135.4102\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_feature_name: diff</text>\n<text text-anchor=\"middle\" x=\"3065.3209\" y=\"-120.4102\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">threshold: 2.35074326114288</text>\n</g>\n<!-- split13&#45;&gt;split27 -->\n<g id=\"edge18\" class=\"edge\">\n<title>split13&#45;&gt;split27</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3351.4529,-213.4941C3292.7757,-196.7021 3213.095,-173.8995 3152.7186,-156.6213\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3153.3987,-153.1754 3142.8216,-153.789 3151.4727,-159.9053 3153.3987,-153.1754\"/>\n<text text-anchor=\"middle\" x=\"3278.8209\" y=\"-180.2802\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;=</text>\n</g>\n<!-- split23 -->\n<g id=\"node23\" class=\"node\">\n<title>split23</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"3431.3209\" cy=\"-131.6102\" rx=\"149.8133\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"3431.3209\" y=\"-135.4102\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_feature_name: bid1vol</text>\n<text text-anchor=\"middle\" x=\"3431.3209\" y=\"-120.4102\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">threshold: &#45;0.5461919001919112</text>\n</g>\n<!-- split13&#45;&gt;split23 -->\n<g id=\"edge21\" class=\"edge\">\n<title>split13&#45;&gt;split23</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3431.3209,-209.3771C3431.3209,-197.0377 3431.3209,-182.2162 3431.3209,-168.8373\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3434.8209,-168.4919 3431.3209,-158.4919 3427.8209,-168.492 3434.8209,-168.4919\"/>\n<text text-anchor=\"middle\" x=\"3435.8209\" y=\"-180.2802\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;</text>\n</g>\n<!-- leaf3 -->\n<g id=\"node21\" class=\"node\">\n<title>leaf3</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"2739.3209\" cy=\"-26.8701\" rx=\"151.1419\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"2739.3209\" y=\"-30.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_index: 3</text>\n<text text-anchor=\"middle\" x=\"2739.3209\" y=\"-15.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_value: 0.3766479079765858</text>\n</g>\n<!-- split27&#45;&gt;leaf3 -->\n<g id=\"edge16\" class=\"edge\">\n<title>split27&#45;&gt;leaf3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2993.7788,-108.6245C2943.2269,-92.3828 2875.3226,-70.5659 2822.3759,-53.5547\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2823.2626,-50.1634 2812.6713,-50.4367 2821.1213,-56.8279 2823.2626,-50.1634\"/>\n<text text-anchor=\"middle\" x=\"2930.8209\" y=\"-75.5401\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;=</text>\n</g>\n<!-- leaf28 -->\n<g id=\"node22\" class=\"node\">\n<title>leaf28</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"3065.3209\" cy=\"-26.8701\" rx=\"156.0415\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"3065.3209\" y=\"-30.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_index: 28</text>\n<text text-anchor=\"middle\" x=\"3065.3209\" y=\"-15.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_value: 0.39041243404621917</text>\n</g>\n<!-- split27&#45;&gt;leaf28 -->\n<g id=\"edge17\" class=\"edge\">\n<title>split27&#45;&gt;leaf28</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3065.3209,-104.637C3065.3209,-92.2976 3065.3209,-77.4761 3065.3209,-64.0972\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3068.8209,-63.7518 3065.3209,-53.7518 3061.8209,-63.7519 3068.8209,-63.7518\"/>\n<text text-anchor=\"middle\" x=\"3069.8209\" y=\"-75.5401\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;</text>\n</g>\n<!-- leaf14 -->\n<g id=\"node24\" class=\"node\">\n<title>leaf14</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"3396.3209\" cy=\"-26.8701\" rx=\"156.0415\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"3396.3209\" y=\"-30.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_index: 14</text>\n<text text-anchor=\"middle\" x=\"3396.3209\" y=\"-15.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_value: 0.36447368953164067</text>\n</g>\n<!-- split23&#45;&gt;leaf14 -->\n<g id=\"edge19\" class=\"edge\">\n<title>split23&#45;&gt;leaf14</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3422.3075,-104.637C3418.1025,-92.0532 3413.0349,-76.8881 3408.4957,-63.3041\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3411.7927,-62.127 3405.3037,-53.7518 3405.1535,-64.3456 3411.7927,-62.127\"/>\n<text text-anchor=\"middle\" x=\"3424.8209\" y=\"-75.5401\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;=</text>\n</g>\n<!-- leaf24 -->\n<g id=\"node25\" class=\"node\">\n<title>leaf24</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"3722.3209\" cy=\"-26.8701\" rx=\"151.1419\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"3722.3209\" y=\"-30.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_index: 24</text>\n<text text-anchor=\"middle\" x=\"3722.3209\" y=\"-15.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_value: 0.3710695980520332</text>\n</g>\n<!-- split23&#45;&gt;leaf24 -->\n<g id=\"edge20\" class=\"edge\">\n<title>split23&#45;&gt;leaf24</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3498.4475,-107.4492C3542.403,-91.6282 3599.9604,-70.9115 3645.7069,-54.4459\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3647.0565,-57.68 3655.2802,-51.0001 3644.6858,-51.0936 3647.0565,-57.68\"/>\n<text text-anchor=\"middle\" x=\"3598.8209\" y=\"-75.5401\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;</text>\n</g>\n<!-- split22 -->\n<g id=\"node27\" class=\"node\">\n<title>split22</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"4202.3209\" cy=\"-131.6102\" rx=\"150.7276\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"4202.3209\" y=\"-135.4102\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_feature_name: diff_avg_ask</text>\n<text text-anchor=\"middle\" x=\"4202.3209\" y=\"-120.4102\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">threshold: &#45;1.4844627525421539</text>\n</g>\n<!-- split18&#45;&gt;split22 -->\n<g id=\"edge25\" class=\"edge\">\n<title>split18&#45;&gt;split22</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M4202.3209,-209.3771C4202.3209,-197.0377 4202.3209,-182.2162 4202.3209,-168.8373\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"4205.8209,-168.4919 4202.3209,-158.4919 4198.8209,-168.492 4205.8209,-168.4919\"/>\n<text text-anchor=\"middle\" x=\"4210.8209\" y=\"-180.2802\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;=</text>\n</g>\n<!-- split29 -->\n<g id=\"node30\" class=\"node\">\n<title>split29</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"4704.3209\" cy=\"-131.6102\" rx=\"147.5709\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"4704.3209\" y=\"-135.4102\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_feature_name: diff_avg_bid</text>\n<text text-anchor=\"middle\" x=\"4704.3209\" y=\"-120.4102\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">threshold: 0.2269017748296816</text>\n</g>\n<!-- split18&#45;&gt;split29 -->\n<g id=\"edge28\" class=\"edge\">\n<title>split18&#45;&gt;split29</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M4299.7067,-216.0311C4385.0902,-198.2163 4509.008,-172.3613 4597.1757,-153.9655\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"4598.1317,-157.3415 4607.206,-151.8728 4596.7019,-150.4891 4598.1317,-157.3415\"/>\n<text text-anchor=\"middle\" x=\"4488.8209\" y=\"-180.2802\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;</text>\n</g>\n<!-- leaf9 -->\n<g id=\"node28\" class=\"node\">\n<title>leaf9</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"4048.3209\" cy=\"-26.8701\" rx=\"156.0415\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"4048.3209\" y=\"-30.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_index: 9</text>\n<text text-anchor=\"middle\" x=\"4048.3209\" y=\"-15.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_value: 0.38647852171773367</text>\n</g>\n<!-- split22&#45;&gt;leaf9 -->\n<g id=\"edge23\" class=\"edge\">\n<title>split22&#45;&gt;leaf9</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M4163.8574,-105.45C4143.094,-91.3282 4117.2936,-73.7806 4095.3442,-58.8521\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"4097.0648,-55.7895 4086.8277,-53.0597 4093.1281,-61.5777 4097.0648,-55.7895\"/>\n<text text-anchor=\"middle\" x=\"4143.8209\" y=\"-75.5401\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;=</text>\n</g>\n<!-- leaf23 -->\n<g id=\"node29\" class=\"node\">\n<title>leaf23</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"4379.3209\" cy=\"-26.8701\" rx=\"156.0415\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"4379.3209\" y=\"-30.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_index: 23</text>\n<text text-anchor=\"middle\" x=\"4379.3209\" y=\"-15.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_value: 0.37724868015607615</text>\n</g>\n<!-- split22&#45;&gt;leaf23 -->\n<g id=\"edge24\" class=\"edge\">\n<title>split22&#45;&gt;leaf23</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M4246.0737,-105.7194C4270.4327,-91.3048 4300.9295,-73.2583 4326.598,-58.0689\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"4328.6343,-60.9309 4335.4579,-52.826 4325.0694,-54.9066 4328.6343,-60.9309\"/>\n<text text-anchor=\"middle\" x=\"4306.8209\" y=\"-75.5401\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;</text>\n</g>\n<!-- leaf19 -->\n<g id=\"node31\" class=\"node\">\n<title>leaf19</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"4704.3209\" cy=\"-26.8701\" rx=\"150.7276\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"4704.3209\" y=\"-30.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_index: 19</text>\n<text text-anchor=\"middle\" x=\"4704.3209\" y=\"-15.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_value: 0.3958762510247119</text>\n</g>\n<!-- split29&#45;&gt;leaf19 -->\n<g id=\"edge26\" class=\"edge\">\n<title>split29&#45;&gt;leaf19</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M4704.3209,-104.637C4704.3209,-92.2976 4704.3209,-77.4761 4704.3209,-64.0972\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"4707.8209,-63.7518 4704.3209,-53.7518 4700.8209,-63.7519 4707.8209,-63.7518\"/>\n<text text-anchor=\"middle\" x=\"4712.8209\" y=\"-75.5401\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;=</text>\n</g>\n<!-- leaf30 -->\n<g id=\"node32\" class=\"node\">\n<title>leaf30</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"5029.3209\" cy=\"-26.8701\" rx=\"156.0415\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"5029.3209\" y=\"-30.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_index: 30</text>\n<text text-anchor=\"middle\" x=\"5029.3209\" y=\"-15.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_value: 0.38213177556770883</text>\n</g>\n<!-- split29&#45;&gt;leaf30 -->\n<g id=\"edge27\" class=\"edge\">\n<title>split29&#45;&gt;leaf30</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M4777.2572,-108.1044C4827.2935,-91.9789 4893.8056,-70.5435 4945.9428,-53.7409\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"4947.0592,-57.0585 4955.5035,-50.6597 4944.9119,-50.3959 4947.0592,-57.0585\"/>\n<text text-anchor=\"middle\" x=\"4890.8209\" y=\"-75.5401\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;</text>\n</g>\n<!-- split4 -->\n<g id=\"node34\" class=\"node\">\n<title>split4</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"6315.3209\" cy=\"-341.0904\" rx=\"149.8133\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"6315.3209\" y=\"-344.8904\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_feature_name: bid1vol</text>\n<text text-anchor=\"middle\" x=\"6315.3209\" y=\"-329.8904\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">threshold: &#45;0.3119674843097728</text>\n</g>\n<!-- split1&#45;&gt;split4 -->\n<g id=\"edge46\" class=\"edge\">\n<title>split1&#45;&gt;split4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M6315.3209,-418.8573C6315.3209,-406.5179 6315.3209,-391.6964 6315.3209,-378.3175\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"6318.8209,-377.9721 6315.3209,-367.9722 6311.8209,-377.9722 6318.8209,-377.9721\"/>\n<text text-anchor=\"middle\" x=\"6323.8209\" y=\"-389.7605\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;=</text>\n</g>\n<!-- split3 -->\n<g id=\"node49\" class=\"node\">\n<title>split3</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"8304.3209\" cy=\"-341.0904\" rx=\"165.426\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"8304.3209\" y=\"-344.8904\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_feature_name: ask1vol</text>\n<text text-anchor=\"middle\" x=\"8304.3209\" y=\"-329.8904\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">threshold: 1.0000000180025095e&#45;35</text>\n</g>\n<!-- split1&#45;&gt;split3 -->\n<g id=\"edge61\" class=\"edge\">\n<title>split1&#45;&gt;split3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M6464.4122,-437.9794C6827.4487,-418.862 7755.4305,-369.9948 8136.8053,-349.9117\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"8137.0184,-353.4054 8146.8205,-349.3843 8136.6502,-346.4151 8137.0184,-353.4054\"/>\n<text text-anchor=\"middle\" x=\"7433.8209\" y=\"-389.7605\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;</text>\n</g>\n<!-- split11 -->\n<g id=\"node35\" class=\"node\">\n<title>split11</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"6073.3209\" cy=\"-236.3503\" rx=\"147.5709\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"6073.3209\" y=\"-240.1503\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_feature_name: diff_avg_ask</text>\n<text text-anchor=\"middle\" x=\"6073.3209\" y=\"-225.1503\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">threshold: 0.5993092491682451</text>\n</g>\n<!-- split4&#45;&gt;split11 -->\n<g id=\"edge38\" class=\"edge\">\n<title>split4&#45;&gt;split11</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M6257.6633,-316.1356C6222.3502,-300.8517 6177.0129,-281.2293 6140.1372,-265.2691\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"6141.5232,-262.0553 6130.9556,-261.2952 6138.7427,-268.4794 6141.5232,-262.0553\"/>\n<text text-anchor=\"middle\" x=\"6217.8209\" y=\"-285.0203\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;=</text>\n</g>\n<!-- split9 -->\n<g id=\"node42\" class=\"node\">\n<title>split9</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"6769.3209\" cy=\"-236.3503\" rx=\"165.426\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"6769.3209\" y=\"-240.1503\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_feature_name: ask1vol</text>\n<text text-anchor=\"middle\" x=\"6769.3209\" y=\"-225.1503\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">threshold: 1.0000000180025095e&#45;35</text>\n</g>\n<!-- split4&#45;&gt;split9 -->\n<g id=\"edge45\" class=\"edge\">\n<title>split4&#45;&gt;split9</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M6407.468,-319.8316C6481.7852,-302.6862 6586.3524,-278.562 6663.9791,-260.6532\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"6664.8298,-264.0489 6673.787,-258.3904 6663.2562,-257.2281 6664.8298,-264.0489\"/>\n<text text-anchor=\"middle\" x=\"6574.8209\" y=\"-285.0203\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;</text>\n</g>\n<!-- split21 -->\n<g id=\"node36\" class=\"node\">\n<title>split21</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"5653.3209\" cy=\"-131.6102\" rx=\"156.0415\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"5653.3209\" y=\"-135.4102\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_feature_name: ask1vol</text>\n<text text-anchor=\"middle\" x=\"5653.3209\" y=\"-120.4102\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">threshold: &#45;0.30803408302426916</text>\n</g>\n<!-- split11&#45;&gt;split21 -->\n<g id=\"edge34\" class=\"edge\">\n<title>split11&#45;&gt;split21</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M5986.0416,-214.5845C5917.8664,-197.5829 5823.1074,-173.9517 5752.146,-156.2553\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"5752.846,-152.8228 5742.2962,-153.799 5751.1522,-159.6147 5752.846,-152.8228\"/>\n<text text-anchor=\"middle\" x=\"5897.8209\" y=\"-180.2802\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;=</text>\n</g>\n<!-- split17 -->\n<g id=\"node39\" class=\"node\">\n<title>split17</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"6073.3209\" cy=\"-131.6102\" rx=\"165.426\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"6073.3209\" y=\"-135.4102\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_feature_name: ask1vol</text>\n<text text-anchor=\"middle\" x=\"6073.3209\" y=\"-120.4102\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">threshold: 1.0000000180025095e&#45;35</text>\n</g>\n<!-- split11&#45;&gt;split17 -->\n<g id=\"edge37\" class=\"edge\">\n<title>split11&#45;&gt;split17</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M6073.3209,-209.3771C6073.3209,-197.0377 6073.3209,-182.2162 6073.3209,-168.8373\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"6076.8209,-168.4919 6073.3209,-158.4919 6069.8209,-168.492 6076.8209,-168.4919\"/>\n<text text-anchor=\"middle\" x=\"6077.8209\" y=\"-180.2802\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;</text>\n</g>\n<!-- leaf1 -->\n<g id=\"node37\" class=\"node\">\n<title>leaf1</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"5349.3209\" cy=\"-26.8701\" rx=\"145.8282\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"5349.3209\" y=\"-30.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_index: 1</text>\n<text text-anchor=\"middle\" x=\"5349.3209\" y=\"-15.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_value: 0.348396176953946</text>\n</g>\n<!-- split21&#45;&gt;leaf1 -->\n<g id=\"edge32\" class=\"edge\">\n<title>split21&#45;&gt;leaf1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M5583.1954,-107.4492C5536.8521,-91.4821 5476.0356,-70.5283 5428.0363,-53.9907\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"5428.902,-50.5871 5418.3072,-50.6386 5426.6217,-57.2053 5428.902,-50.5871\"/>\n<text text-anchor=\"middle\" x=\"5528.8209\" y=\"-75.5401\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;=</text>\n</g>\n<!-- leaf22 -->\n<g id=\"node38\" class=\"node\">\n<title>leaf22</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"5653.3209\" cy=\"-26.8701\" rx=\"140.9288\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"5653.3209\" y=\"-30.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_index: 22</text>\n<text text-anchor=\"middle\" x=\"5653.3209\" y=\"-15.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_value: 0.34301082061733</text>\n</g>\n<!-- split21&#45;&gt;leaf22 -->\n<g id=\"edge33\" class=\"edge\">\n<title>split21&#45;&gt;leaf22</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M5653.3209,-104.637C5653.3209,-92.2976 5653.3209,-77.4761 5653.3209,-64.0972\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"5656.8209,-63.7518 5653.3209,-53.7518 5649.8209,-63.7519 5656.8209,-63.7518\"/>\n<text text-anchor=\"middle\" x=\"5657.8209\" y=\"-75.5401\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;</text>\n</g>\n<!-- leaf12 -->\n<g id=\"node40\" class=\"node\">\n<title>leaf12</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"5963.3209\" cy=\"-26.8701\" rx=\"151.1419\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"5963.3209\" y=\"-30.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_index: 12</text>\n<text text-anchor=\"middle\" x=\"5963.3209\" y=\"-15.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_value: 0.3427805128176661</text>\n</g>\n<!-- split17&#45;&gt;leaf12 -->\n<g id=\"edge35\" class=\"edge\">\n<title>split17&#45;&gt;leaf12</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M6045.2786,-104.9088C6031.1855,-91.4896 6013.955,-75.083 5998.936,-60.7822\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"6000.9676,-57.8837 5991.3119,-53.5227 5996.1405,-62.9532 6000.9676,-57.8837\"/>\n<text text-anchor=\"middle\" x=\"6033.8209\" y=\"-75.5401\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;=</text>\n</g>\n<!-- leaf18 -->\n<g id=\"node41\" class=\"node\">\n<title>leaf18</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"6289.3209\" cy=\"-26.8701\" rx=\"156.0415\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"6289.3209\" y=\"-30.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_index: 18</text>\n<text text-anchor=\"middle\" x=\"6289.3209\" y=\"-15.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_value: 0.33468531056639644</text>\n</g>\n<!-- split17&#45;&gt;leaf18 -->\n<g id=\"edge36\" class=\"edge\">\n<title>split17&#45;&gt;leaf18</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M6125.8842,-106.1218C6156.5715,-91.2413 6195.4515,-72.3881 6227.5904,-56.8036\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"6229.4257,-59.8035 6236.8965,-52.291 6226.3715,-53.505 6229.4257,-59.8035\"/>\n<text text-anchor=\"middle\" x=\"6198.8209\" y=\"-75.5401\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;</text>\n</g>\n<!-- split20 -->\n<g id=\"node43\" class=\"node\">\n<title>split20</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"6769.3209\" cy=\"-131.6102\" rx=\"147.5709\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"6769.3209\" y=\"-135.4102\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_feature_name: bid1vol</text>\n<text text-anchor=\"middle\" x=\"6769.3209\" y=\"-120.4102\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">threshold: 0.6249301792187815</text>\n</g>\n<!-- split9&#45;&gt;split20 -->\n<g id=\"edge41\" class=\"edge\">\n<title>split9&#45;&gt;split20</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M6769.3209,-209.3771C6769.3209,-197.0377 6769.3209,-182.2162 6769.3209,-168.8373\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"6772.8209,-168.4919 6769.3209,-158.4919 6765.8209,-168.492 6772.8209,-168.4919\"/>\n<text text-anchor=\"middle\" x=\"6777.8209\" y=\"-180.2802\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;=</text>\n</g>\n<!-- split15 -->\n<g id=\"node46\" class=\"node\">\n<title>split15</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"7260.3209\" cy=\"-131.6102\" rx=\"150.7276\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"7260.3209\" y=\"-135.4102\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_feature_name: diff_avg_ask</text>\n<text text-anchor=\"middle\" x=\"7260.3209\" y=\"-120.4102\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">threshold: &#45;0.0078800425325062</text>\n</g>\n<!-- split9&#45;&gt;split15 -->\n<g id=\"edge44\" class=\"edge\">\n<title>split9&#45;&gt;split15</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M6869.5702,-214.9651C6952.2628,-197.3251 7069.2878,-172.3614 7153.6861,-154.3575\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"7154.5037,-157.7619 7163.5535,-152.2526 7153.0433,-150.9159 7154.5037,-157.7619\"/>\n<text text-anchor=\"middle\" x=\"7048.8209\" y=\"-180.2802\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;</text>\n</g>\n<!-- leaf5 -->\n<g id=\"node44\" class=\"node\">\n<title>leaf5</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"6609.3209\" cy=\"-26.8701\" rx=\"145.8282\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"6609.3209\" y=\"-30.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_index: 5</text>\n<text text-anchor=\"middle\" x=\"6609.3209\" y=\"-15.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_value: 0.353454464432514</text>\n</g>\n<!-- split20&#45;&gt;leaf5 -->\n<g id=\"edge39\" class=\"edge\">\n<title>split20&#45;&gt;leaf5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M6729.7703,-105.7194C6707.9431,-91.4307 6680.6642,-73.5733 6657.5889,-58.4675\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"6659.2547,-55.3748 6648.971,-52.826 6655.4207,-61.2315 6659.2547,-55.3748\"/>\n<text text-anchor=\"middle\" x=\"6707.8209\" y=\"-75.5401\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;=</text>\n</g>\n<!-- leaf21 -->\n<g id=\"node45\" class=\"node\">\n<title>leaf21</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"6929.3209\" cy=\"-26.8701\" rx=\"156.0415\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"6929.3209\" y=\"-30.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_index: 21</text>\n<text text-anchor=\"middle\" x=\"6929.3209\" y=\"-15.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_value: 0.36046198603769497</text>\n</g>\n<!-- split20&#45;&gt;leaf21 -->\n<g id=\"edge40\" class=\"edge\">\n<title>split20&#45;&gt;leaf21</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M6808.8714,-105.7194C6830.6166,-91.4844 6857.7725,-73.7075 6880.7924,-58.638\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"6882.9429,-61.4136 6889.3926,-53.0081 6879.1089,-55.5569 6882.9429,-61.4136\"/>\n<text text-anchor=\"middle\" x=\"6863.8209\" y=\"-75.5401\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;</text>\n</g>\n<!-- leaf10 -->\n<g id=\"node47\" class=\"node\">\n<title>leaf10</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"7260.3209\" cy=\"-26.8701\" rx=\"156.0415\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"7260.3209\" y=\"-30.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_index: 10</text>\n<text text-anchor=\"middle\" x=\"7260.3209\" y=\"-15.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_value: 0.35261428865096944</text>\n</g>\n<!-- split15&#45;&gt;leaf10 -->\n<g id=\"edge42\" class=\"edge\">\n<title>split15&#45;&gt;leaf10</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M7260.3209,-104.637C7260.3209,-92.2976 7260.3209,-77.4761 7260.3209,-64.0972\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"7263.8209,-63.7518 7260.3209,-53.7518 7256.8209,-63.7519 7263.8209,-63.7518\"/>\n<text text-anchor=\"middle\" x=\"7268.8209\" y=\"-75.5401\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;=</text>\n</g>\n<!-- leaf16 -->\n<g id=\"node48\" class=\"node\">\n<title>leaf16</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"7580.3209\" cy=\"-26.8701\" rx=\"145.8282\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"7580.3209\" y=\"-30.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_index: 16</text>\n<text text-anchor=\"middle\" x=\"7580.3209\" y=\"-15.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_value: 0.344228647016875</text>\n</g>\n<!-- split15&#45;&gt;leaf16 -->\n<g id=\"edge43\" class=\"edge\">\n<title>split15&#45;&gt;leaf16</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M7332.5341,-107.9738C7381.9759,-91.7909 7447.6157,-70.3062 7498.9147,-53.5153\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"7500.2312,-56.7672 7508.6463,-50.3301 7498.0537,-50.1145 7500.2312,-56.7672\"/>\n<text text-anchor=\"middle\" x=\"7444.8209\" y=\"-75.5401\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;</text>\n</g>\n<!-- split6 -->\n<g id=\"node50\" class=\"node\">\n<title>split6</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"8304.3209\" cy=\"-236.3503\" rx=\"152.0559\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"8304.3209\" y=\"-240.1503\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_feature_name: transacted_qty</text>\n<text text-anchor=\"middle\" x=\"8304.3209\" y=\"-225.1503\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">threshold: &#45;0.4998847621904657</text>\n</g>\n<!-- split3&#45;&gt;split6 -->\n<g id=\"edge53\" class=\"edge\">\n<title>split3&#45;&gt;split6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M8304.3209,-314.1172C8304.3209,-301.7778 8304.3209,-286.9563 8304.3209,-273.5774\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"8307.8209,-273.232 8304.3209,-263.2321 8300.8209,-273.2321 8307.8209,-273.232\"/>\n<text text-anchor=\"middle\" x=\"8312.8209\" y=\"-285.0203\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;=</text>\n</g>\n<!-- split5 -->\n<g id=\"node57\" class=\"node\">\n<title>split5</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"9331.3209\" cy=\"-236.3503\" rx=\"156.0415\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"9331.3209\" y=\"-240.1503\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_feature_name: transacted_qty</text>\n<text text-anchor=\"middle\" x=\"9331.3209\" y=\"-225.1503\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">threshold: &#45;0.23541030480882244</text>\n</g>\n<!-- split3&#45;&gt;split5 -->\n<g id=\"edge60\" class=\"edge\">\n<title>split3&#45;&gt;split5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M8444.6991,-326.7737C8639.4111,-306.9157 8989.6727,-271.1938 9186.6441,-251.1054\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"9187.1844,-254.5685 9196.7777,-250.0719 9186.4741,-247.6046 9187.1844,-254.5685\"/>\n<text text-anchor=\"middle\" x=\"8883.8209\" y=\"-285.0203\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;</text>\n</g>\n<!-- split19 -->\n<g id=\"node51\" class=\"node\">\n<title>split19</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"8220.3209\" cy=\"-131.6102\" rx=\"165.426\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"8220.3209\" y=\"-135.4102\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_feature_name: bid1vol</text>\n<text text-anchor=\"middle\" x=\"8220.3209\" y=\"-120.4102\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">threshold: 1.0000000180025095e&#45;35</text>\n</g>\n<!-- split6&#45;&gt;split19 -->\n<g id=\"edge49\" class=\"edge\">\n<title>split6&#45;&gt;split19</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M8282.9068,-209.6489C8272.3422,-196.4759 8259.469,-180.4242 8248.1509,-166.3116\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"8250.6827,-163.8742 8241.6958,-158.2628 8245.2219,-168.2537 8250.6827,-163.8742\"/>\n<text text-anchor=\"middle\" x=\"8276.8209\" y=\"-180.2802\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;=</text>\n</g>\n<!-- split12 -->\n<g id=\"node54\" class=\"node\">\n<title>split12</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"8553.3209\" cy=\"-131.6102\" rx=\"149.8133\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"8553.3209\" y=\"-135.4102\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_feature_name: bid1vol</text>\n<text text-anchor=\"middle\" x=\"8553.3209\" y=\"-120.4102\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">threshold: &#45;0.3119674843097728</text>\n</g>\n<!-- split6&#45;&gt;split12 -->\n<g id=\"edge52\" class=\"edge\">\n<title>split6&#45;&gt;split12</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M8363.3304,-211.5283C8399.7894,-196.1921 8446.7234,-176.4496 8484.8204,-160.4244\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"8486.4433,-163.5389 8494.3039,-156.4352 8483.7291,-157.0865 8486.4433,-163.5389\"/>\n<text text-anchor=\"middle\" x=\"8448.8209\" y=\"-180.2802\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;</text>\n</g>\n<!-- leaf2 -->\n<g id=\"node52\" class=\"node\">\n<title>leaf2</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"7900.3209\" cy=\"-26.8701\" rx=\"156.0415\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"7900.3209\" y=\"-30.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_index: 2</text>\n<text text-anchor=\"middle\" x=\"7900.3209\" y=\"-15.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_value: 0.35014900788542275</text>\n</g>\n<!-- split19&#45;&gt;leaf2 -->\n<g id=\"edge47\" class=\"edge\">\n<title>split19&#45;&gt;leaf2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M8146.5046,-107.4492C8097.6052,-91.4438 8033.3976,-70.4278 7982.816,-53.8718\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"7983.8063,-50.5133 7973.2137,-50.7288 7981.6288,-57.166 7983.8063,-50.5133\"/>\n<text text-anchor=\"middle\" x=\"8088.8209\" y=\"-75.5401\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;=</text>\n</g>\n<!-- leaf20 -->\n<g id=\"node53\" class=\"node\">\n<title>leaf20</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"8226.3209\" cy=\"-26.8701\" rx=\"151.1419\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"8226.3209\" y=\"-30.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_index: 20</text>\n<text text-anchor=\"middle\" x=\"8226.3209\" y=\"-15.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_value: 0.3587399921317142</text>\n</g>\n<!-- split19&#45;&gt;leaf20 -->\n<g id=\"edge48\" class=\"edge\">\n<title>split19&#45;&gt;leaf20</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M8221.866,-104.637C8222.5729,-92.2976 8223.4219,-77.4761 8224.1883,-64.0972\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"8227.7032,-63.9357 8224.7809,-53.7518 8220.7147,-63.5353 8227.7032,-63.9357\"/>\n<text text-anchor=\"middle\" x=\"8228.8209\" y=\"-75.5401\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;</text>\n</g>\n<!-- leaf7 -->\n<g id=\"node55\" class=\"node\">\n<title>leaf7</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"8547.3209\" cy=\"-26.8701\" rx=\"151.1419\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"8547.3209\" y=\"-30.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_index: 7</text>\n<text text-anchor=\"middle\" x=\"8547.3209\" y=\"-15.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_value: 0.3596213700495049</text>\n</g>\n<!-- split12&#45;&gt;leaf7 -->\n<g id=\"edge50\" class=\"edge\">\n<title>split12&#45;&gt;leaf7</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M8551.7757,-104.637C8551.0688,-92.2976 8550.2198,-77.4761 8549.4534,-64.0972\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"8552.927,-63.5353 8548.8608,-53.7518 8545.9385,-63.9357 8552.927,-63.5353\"/>\n<text text-anchor=\"middle\" x=\"8559.8209\" y=\"-75.5401\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;=</text>\n</g>\n<!-- leaf13 -->\n<g id=\"node56\" class=\"node\">\n<title>leaf13</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"8862.3209\" cy=\"-26.8701\" rx=\"145.8282\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"8862.3209\" y=\"-30.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_index: 13</text>\n<text text-anchor=\"middle\" x=\"8862.3209\" y=\"-15.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_value: 0.368009096444157</text>\n</g>\n<!-- split12&#45;&gt;leaf13 -->\n<g id=\"edge51\" class=\"edge\">\n<title>split12&#45;&gt;leaf13</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M8623.4377,-107.843C8670.8469,-91.773 8733.5475,-70.5197 8782.8155,-53.8196\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"8784.1343,-57.0682 8792.4814,-50.5432 8781.8871,-50.4387 8784.1343,-57.0682\"/>\n<text text-anchor=\"middle\" x=\"8731.8209\" y=\"-75.5401\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;</text>\n</g>\n<!-- split14 -->\n<g id=\"node58\" class=\"node\">\n<title>split14</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"9331.3209\" cy=\"-131.6102\" rx=\"152.9705\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"9331.3209\" y=\"-135.4102\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_feature_name: diff_avg_ask</text>\n<text text-anchor=\"middle\" x=\"9331.3209\" y=\"-120.4102\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">threshold: 0.20664045321862096</text>\n</g>\n<!-- split5&#45;&gt;split14 -->\n<g id=\"edge56\" class=\"edge\">\n<title>split5&#45;&gt;split14</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M9331.3209,-209.3771C9331.3209,-197.0377 9331.3209,-182.2162 9331.3209,-168.8373\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"9334.8209,-168.4919 9331.3209,-158.4919 9327.8209,-168.492 9334.8209,-168.4919\"/>\n<text text-anchor=\"middle\" x=\"9339.8209\" y=\"-180.2802\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;=</text>\n</g>\n<!-- split10 -->\n<g id=\"node61\" class=\"node\">\n<title>split10</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"9834.3209\" cy=\"-131.6102\" rx=\"150.7276\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"9834.3209\" y=\"-135.4102\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_feature_name: diff_avg_ask</text>\n<text text-anchor=\"middle\" x=\"9834.3209\" y=\"-120.4102\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">threshold: &#45;0.2346615852191706</text>\n</g>\n<!-- split5&#45;&gt;split10 -->\n<g id=\"edge59\" class=\"edge\">\n<title>split5&#45;&gt;split10</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M9430.998,-215.5944C9516.2134,-197.85 9638.5902,-172.3673 9726.1608,-154.1324\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"9727.0499,-157.5225 9736.1264,-152.0573 9725.6228,-150.6695 9727.0499,-157.5225\"/>\n<text text-anchor=\"middle\" x=\"9617.8209\" y=\"-180.2802\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;</text>\n</g>\n<!-- leaf4 -->\n<g id=\"node59\" class=\"node\">\n<title>leaf4</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"9177.3209\" cy=\"-26.8701\" rx=\"151.1419\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"9177.3209\" y=\"-30.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_index: 4</text>\n<text text-anchor=\"middle\" x=\"9177.3209\" y=\"-15.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_value: 0.3508272242175172</text>\n</g>\n<!-- split14&#45;&gt;leaf4 -->\n<g id=\"edge54\" class=\"edge\">\n<title>split14&#45;&gt;leaf4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M9292.8574,-105.45C9272.0154,-91.2747 9246.0981,-73.6476 9224.095,-58.6826\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"9225.7978,-55.6079 9215.5606,-52.8781 9221.861,-61.396 9225.7978,-55.6079\"/>\n<text text-anchor=\"middle\" x=\"9272.8209\" y=\"-75.5401\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;=</text>\n</g>\n<!-- leaf15 -->\n<g id=\"node60\" class=\"node\">\n<title>leaf15</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"9503.3209\" cy=\"-26.8701\" rx=\"156.0415\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"9503.3209\" y=\"-30.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_index: 15</text>\n<text text-anchor=\"middle\" x=\"9503.3209\" y=\"-15.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_value: 0.34294398861759895</text>\n</g>\n<!-- split14&#45;&gt;leaf15 -->\n<g id=\"edge55\" class=\"edge\">\n<title>split14&#45;&gt;leaf15</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M9373.8377,-105.7194C9397.5087,-91.3048 9427.1439,-73.2583 9452.0873,-58.0689\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"9453.9764,-61.0165 9460.697,-52.826 9450.3356,-55.0378 9453.9764,-61.0165\"/>\n<text text-anchor=\"middle\" x=\"9432.8209\" y=\"-75.5401\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;</text>\n</g>\n<!-- leaf6 -->\n<g id=\"node62\" class=\"node\">\n<title>leaf6</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"9834.3209\" cy=\"-26.8701\" rx=\"156.0415\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"9834.3209\" y=\"-30.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_index: 6</text>\n<text text-anchor=\"middle\" x=\"9834.3209\" y=\"-15.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_value: 0.36438853655682507</text>\n</g>\n<!-- split10&#45;&gt;leaf6 -->\n<g id=\"edge57\" class=\"edge\">\n<title>split10&#45;&gt;leaf6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M9834.3209,-104.637C9834.3209,-92.2976 9834.3209,-77.4761 9834.3209,-64.0972\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"9837.8209,-63.7518 9834.3209,-53.7518 9830.8209,-63.7519 9837.8209,-63.7518\"/>\n<text text-anchor=\"middle\" x=\"9842.8209\" y=\"-75.5401\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;=</text>\n</g>\n<!-- leaf11 -->\n<g id=\"node63\" class=\"node\">\n<title>leaf11</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"10165.3209\" cy=\"-26.8701\" rx=\"156.0415\" ry=\"26.7407\"/>\n<text text-anchor=\"middle\" x=\"10165.3209\" y=\"-30.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_index: 11</text>\n<text text-anchor=\"middle\" x=\"10165.3209\" y=\"-15.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">leaf_value: 0.35329324184173255</text>\n</g>\n<!-- split10&#45;&gt;leaf11 -->\n<g id=\"edge58\" class=\"edge\">\n<title>split10&#45;&gt;leaf11</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M9908.6037,-108.1044C9959.6535,-91.9505 10027.5424,-70.468 10080.6838,-53.6522\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"10081.9494,-56.9229 10090.4275,-50.569 10079.8375,-50.249 10081.9494,-56.9229\"/>\n<text text-anchor=\"middle\" x=\"10024.8209\" y=\"-75.5401\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;</text>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C386xY_B_kJX",
        "colab_type": "code",
        "outputId": "785d378f-19c4-4d6a-fc51-30c7d6b1f946",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "#check eff sprread\n",
        "print(X_train.columns)\n",
        "d_train = lgb.Dataset(X_train, label=y_train)\n",
        "param = {\"max_depth\": 5, \"learning_rate\": 0.1, \"num_leaves\": 900, \"n_estimators\": 100}\n",
        "model2 = lgb.train(params=param,train_set=d_train)\n",
        "# print(‘Plot feature importances…’)\n",
        "plt.figure(figsize=(50,25))\n",
        "ax = lgb.plot_importance(model2, max_num_features=33)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c3fb56b96c6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0md_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"max_depth\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"learning_rate\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"num_leaves\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m900\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_estimators\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# print(‘Plot feature importances…’)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ErCE-VRdUSe",
        "colab_type": "code",
        "outputId": "7b99399a-5156-42a2-9593-25b10684cea6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "model_3 = Sequential([\n",
        "      Dense(1000, activation='relu',input_shape=(21,)),\n",
        "      Dropout(0.2),\n",
        "      Dense(500, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(200, activation='relu'),\n",
        "      Dense(1, activation='sigmoid'),\n",
        "  ])\n",
        "model_3.compile(optimizer='adam',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "hist_3 = model_3.fit(X_train, y_train,\n",
        "            batch_size=32, epochs=10,\n",
        "            validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-1961ecb4b325>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model_3 = Sequential([\n\u001b[0m\u001b[1;32m      2\u001b[0m       \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m       \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tqkGQ_alQB-",
        "colab_type": "code",
        "outputId": "7d8a8bee-93d8-44ad-faa0-08387697b692",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "model_3 = Sequential([\n",
        "      Dense(5000, activation='relu',input_shape=(21,)),\n",
        "      Dropout(0.1),\n",
        "      Dense(5000, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(5000, activation='relu'),\n",
        "      Dense(1, activation='sigmoid'),\n",
        "  ])\n",
        "model_3.compile(optimizer='adam',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy',auroc])\n",
        "hist_3 = model_3.fit(X_train, y_train,\n",
        "            batch_size=32, epochs=10,\n",
        "            validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 473904 samples, validate on 118476 samples\n",
            "Epoch 1/10\n",
            " 54336/473904 [==>...........................] - ETA: 2:54:38 - loss: 0.6305 - acc: 0.6532 - auroc: 0.6433"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wV29xaGJhT0",
        "colab_type": "code",
        "outputId": "d0129232-eb19-484e-d26e-f9e3162a9509",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "probbs = model_3.predict_proba(X_test)\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def auroc(y_true, y_pred):\n",
        "    return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)\n",
        "\n",
        "auroc(y_test,probbs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-8-fb05f748c1e4>:12: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'PyFunc:0' shape=<unknown> dtype=float64>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GHfUiLQlCFW",
        "colab_type": "code",
        "outputId": "4d645ec4-e18a-42a9-d9f5-52289aa0fdf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "#predict on test\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "df_test = test_df.fillna(test_df.median())\n",
        "\n",
        "\n",
        "df_test['diff'] = (df_test['last_price'] - df_test['mid'])\n",
        "df_test['avg_bid'] = (df_test['bid1'] * df_test['bid1vol'] + df_test['bid2'] * df_test['bid2vol'] + df_test['bid3'] * df_test['bid3vol'] + df_test['bid4'] * df_test['bid4vol'] + df_test['bid5'] * df_test['bid5vol']) / (df_test['bid1vol'] + df_test['bid2vol'] + df_test['bid3vol'] + df_test['bid4vol'] + df_test['bid5vol'])\n",
        "df_test['avg_ask'] = (df_test['ask1'] * df_test['ask1vol'] + df_test['ask2'] * df_test['ask2vol'] + df_test['ask3'] * df_test['ask3vol'] + df_test['ask4'] * df_test['ask4vol'] + df_test['ask5'] * df_test['ask5vol']) / (df_test['ask1vol'] + df_test['ask2vol'] + df_test['ask3vol'] + df_test['ask4vol'] + df_test['ask5vol'])\n",
        "df_test['diff_avg_bid'] = (df_test['mid'] - df_test['avg_bid'])\n",
        "df_test['diff_avg_ask'] = (df_test['mid'] - df_test['avg_ask'])\n",
        "df_test = df_test.drop(['id', 'bid1', 'bid2', 'bid3', 'bid4', 'bid5', 'ask1', 'ask2','ask3','ask4','ask5'], axis=1)\n",
        "normalized_X_test =(df_test-df_test.mean())/df_test.std()\n",
        "probbs = model_3.predict_proba(normalized_X_test)\n",
        "test_df['Predicted'] = probbs\n",
        "header = [\"id\", \"Predicted\"]\n",
        "test_df.to_csv('output.csv', columns = header,index=False)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-96464c32b565>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dj1n-ylAoDdd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normalized_X.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k4lSG5N8lZe",
        "colab_type": "code",
        "outputId": "84755928-186b-4c3e-81ea-d49f97382ba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "normalized_X_test.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Predicted', 'ask1vol', 'ask2vol', 'ask3vol', 'ask4vol', 'ask5vol',\n",
              "       'avg_ask', 'avg_bid', 'bid1vol', 'bid2vol', 'bid3vol', 'bid4vol',\n",
              "       'bid5vol', 'closed_position_qty', 'd_open_interest', 'diff',\n",
              "       'diff_avg_ask', 'diff_avg_bid', 'last_price', 'mid',\n",
              "       'opened_position_qty ', 'probs', 'transacted_qty'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4tHkyOH6RlB",
        "colab_type": "code",
        "outputId": "fa004537-3964-46f6-f0e7-53e7aa3fd16a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "np.array(test_df['id'],probbs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-7c26cfd594a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprobbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: data type not understood"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Fi1vgja6o1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df['Predicted'] = probbs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KCns0hR6sYe",
        "colab_type": "code",
        "outputId": "097629f7-1db5-4c55-c0c8-ff9cdd94c841",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(test_df['id'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "191859"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBawXlG061pb",
        "colab_type": "code",
        "outputId": "43a2a423-64d4-46c4-adcc-4747ee3e38ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(probbs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "592380"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLdLO8nn63GP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df['Predicted'] = probbs\n",
        "header = [\"id\", \"Predicted\"]\n",
        "test_df.to_csv('output.csv', columns = header,index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqXHEUwM7fiU",
        "colab_type": "code",
        "outputId": "e609e600-87da-4d8d-9748-9d000b8b3ecf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "pd.read_csv('output.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>592380</td>\n",
              "      <td>2.704272e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>592381</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>592382</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>592383</td>\n",
              "      <td>7.152557e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>592384</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191854</th>\n",
              "      <td>784234</td>\n",
              "      <td>5.960464e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191855</th>\n",
              "      <td>784235</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191856</th>\n",
              "      <td>784236</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191857</th>\n",
              "      <td>784237</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191858</th>\n",
              "      <td>784238</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>191859 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            id     Predicted\n",
              "0       592380  2.704272e-01\n",
              "1       592381  0.000000e+00\n",
              "2       592382  0.000000e+00\n",
              "3       592383  7.152557e-05\n",
              "4       592384  0.000000e+00\n",
              "...        ...           ...\n",
              "191854  784234  5.960464e-08\n",
              "191855  784235  0.000000e+00\n",
              "191856  784236  0.000000e+00\n",
              "191857  784237  0.000000e+00\n",
              "191858  784238  0.000000e+00\n",
              "\n",
              "[191859 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYL6OFsh737o",
        "colab_type": "code",
        "outputId": "10ca174b-8d40-4195-c089-6ce5ce873989",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from boruta import BorutaPy\n",
        "rfc = RandomForestClassifier(n_estimators=1000, n_jobs=-1, class_weight='balanced')\n",
        "boruta_selector = BorutaPy(rfc, n_estimators='auto', verbose=2)\n",
        "# x=X_train.iloc[:,:].values\n",
        "# y=y_train.iloc[:,0].values\n",
        "boruta_selector.fit(X_train.values,y_train.values)\n",
        "# print(“==============BORUTA==============”)\n",
        "print (boruta_selector.n_features_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: \t1 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t32\n",
            "Rejected: \t0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-6953a9a6f821>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# x=X_train.iloc[:,:].values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# y=y_train.iloc[:,0].values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mboruta_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# print(“==============BORUTA==============”)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mboruta_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/boruta/boruta_py.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \"\"\"\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweak\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/boruta/boruta_py.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0;31m# add shadow attributes, shuffle them and train estimator, get imps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mcur_imp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_shadows_get_imps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_reg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;31m# get the threshold of shadow importances we will use for rejection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/boruta/boruta_py.py\u001b[0m in \u001b[0;36m_add_shadows_get_imps\u001b[0;34m(self, X, y, dec_reg)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0mx_sha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_along_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_shuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_sha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;31m# get importance of the merged matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0mimp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_imp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_cur\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_sha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m         \u001b[0;31m# separate importances of real and shadow features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mimp_sha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_cur_w\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/boruta/boruta_py.py\u001b[0m in \u001b[0;36m_get_imp\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_imp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             raise ValueError('Please check your X and y variable. The provided'\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 383\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Djk73cc8x4x",
        "colab_type": "code",
        "outputId": "91b5a188-bf2c-4c77-f28e-7473241282e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "pip install boruta"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting boruta\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/11/583f4eac99d802c79af9217e1eff56027742a69e6c866b295cce6a5a8fc2/Boruta-0.3-py3-none-any.whl (56kB)\n",
            "\r\u001b[K     |█████▉                          | 10kB 29.3MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 20kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 30kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 40kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 51kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from boruta) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from boruta) (1.17.5)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from boruta) (0.22.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.17.1->boruta) (0.14.1)\n",
            "Installing collected packages: boruta\n",
            "Successfully installed boruta-0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-mIfwkX84eQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}