{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Pruning and Adding Models to Ensemble.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ag5XD4I2Rxvq",
        "outputId": "ef87684c-16f1-4a31-8597-3a0c84eaef6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dense, Flatten, MaxPooling2D, Dropout,Activation,LSTM\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.svm import *\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, learning_curve, validation_curve, cross_val_score\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier,VotingClassifier,RandomForestClassifier,AdaBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import  roc_auc_score\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "from sklearn.svm import *\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F7MphF4EXkSo",
        "colab": {}
      },
      "source": [
        "def add_fields(df, with_y):\n",
        "  df = df.fillna(0)\n",
        "  df2 = pd.DataFrame()\n",
        "\n",
        "  df2['diff_bid1'] = df['last_price'] - df['bid1']\n",
        "  df2['diff_bid2'] = df['last_price'] - df['bid2']\n",
        "  df2['diff_bid3'] = df['last_price'] - df['bid3']\n",
        "  df2['diff_bid4'] = df['last_price'] - df['bid4']\n",
        "  df2['diff_bid5'] = df['last_price'] - df['bid5']\n",
        "\n",
        "  df2['diff_ask1'] = df['last_price'] - df['ask1']\n",
        "  df2['diff_ask2'] = df['last_price'] - df['ask2']\n",
        "  df2['diff_ask3'] = df['last_price'] - df['ask3']\n",
        "  df2['diff_ask4'] = df['last_price'] - df['ask4']\n",
        "  df2['diff_ask5'] = df['last_price'] - df['ask5']\n",
        "\n",
        "  df2['diff_mid_bid1'] = df['mid'] - df['bid1']\n",
        "  df2['diff_mid_bid2'] = df['mid'] - df['bid2']\n",
        "  df2['diff_mid_bid3'] = df['mid'] - df['bid3']\n",
        "  df2['diff_mid_bid4'] = df['mid'] - df['bid4']\n",
        "  df2['diff_mid_bid5'] = df['mid'] - df['bid5']\n",
        "\n",
        "  df2['diff_mid_ask1'] = df['mid'] - df['ask1']\n",
        "  df2['diff_mid_ask2'] = df['mid'] - df['ask2']\n",
        "  df2['diff_mid_ask3'] = df['mid'] - df['ask3']\n",
        "  df2['diff_mid_ask4'] = df['mid'] - df['ask4']\n",
        "  df2['diff_mid_ask5'] = df['mid'] - df['ask5']\n",
        "\n",
        "  df2['mid_diff'] = df['last_price'] - df['mid']\n",
        "  df2['best_offer_last_price_diff'] = df2['diff_bid1'] + df2['diff_ask1']\n",
        "\n",
        "  df['avg_bid'] = (df['bid1'] * df['bid1vol'] + df['bid2'] * df['bid2vol'] + df['bid3'] * df['bid3vol'] + df['bid4'] * df['bid4vol'] + df['bid5'] * df['bid5vol']) / (df['bid1vol'] + df['bid2vol'] + df['bid3vol'] + df['bid4vol'] + df['bid5vol'])\n",
        "  df['avg_ask'] = (df['ask1'] * df['ask1vol'] + df['ask2'] * df['ask2vol'] + df['ask3'] * df['ask3vol'] + df['ask4'] * df['ask4vol'] + df['ask5'] * df['ask5vol']) / (df['ask1vol'] + df['ask2vol'] + df['ask3vol'] + df['ask4vol'] + df['ask5vol'])\n",
        "\n",
        "  df2['avg_bid_last_price_diff'] = df['avg_bid'] - df['last_price']\n",
        "  df2['avg_bid_mid_diff'] = df['avg_bid'] - df['mid']\n",
        "  df2['avg_ask_last_price_diff'] = df['avg_ask'] - df['last_price']\n",
        "  df2['avg_ask_mid_diff'] = df['avg_ask'] - df['mid']\n",
        "\n",
        "  df2['avg_bid_best_bid_diff'] = df['avg_bid'] - df['bid1']\n",
        "  df2['avg_ask_best_ask_diff'] = df['avg_ask'] - df['ask1']\n",
        "  df2['avg_bid_best_ask_diff'] = df['avg_bid'] - df['ask1']\n",
        "  df2['avg_ask_best_bid_diff'] = df['avg_ask'] - df['bid1']\n",
        "\n",
        "  df2['best_offer_diff'] = df['bid1'] - df['ask1']\n",
        "  df2['best_offer_vol_diff'] = df['bid1vol'] - df['ask1vol']\n",
        "  df2['best_offer_tot_diff'] = df['bid1'] * df['bid1vol'] - df['ask1'] * df['ask1vol']\n",
        "\n",
        "  df['avg_best_offer'] = (df['bid1'] * df['bid1vol'] + df['ask1'] * df['ask1vol']) / (df['bid1vol'] + df['ask1vol'])\n",
        "  df2['mid_avg_best_offer_diff'] = df['mid'] - df['avg_best_offer']\n",
        "  df2['last_price_avg_best_offer_diff'] = df['last_price'] - df['avg_best_offer']\n",
        "\n",
        "  df2['tot_bid_vol'] = df['bid1vol'] + df['bid2vol'] + df['bid3vol'] + df['bid4vol'] + df['bid5vol'] \n",
        "  df2['tot_ask_vol'] = df['ask1vol'] + df['ask2vol'] + df['ask3vol'] + df['ask4vol'] + df['ask5vol'] \n",
        "  df2['tot_offer_vol_diff'] = df2['tot_bid_vol'] - df2['tot_ask_vol']\n",
        "\n",
        "  df2['closed_tot_bid_diff'] = df2['tot_bid_vol'] - df['closed_position_qty']\n",
        "  df2['closed_tot_ask_diff'] = df2['tot_ask_vol'] - df['closed_position_qty']\n",
        "  df2['opened_tot_bid_diff'] = df2['tot_bid_vol'] - df['opened_position_qty ']\n",
        "  df2['opened_tot_ask_diff'] = df2['tot_ask_vol'] - df['opened_position_qty ']\n",
        "\n",
        "  df2['d_open_interest'] = df['d_open_interest'] \n",
        "  df2['transacted_qty'] = df['transacted_qty'] \n",
        "  df2['tot_orders_diff'] = df2['tot_offer_vol_diff'] + df['d_open_interest']\n",
        "\n",
        "\n",
        "  if with_y == True:\n",
        "    y = df['y']\n",
        "  else:\n",
        "    y = []\n",
        "\n",
        "  X = df2.loc[:, df2.columns != 'y']  \n",
        "  return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG7go3Yo0Rly",
        "colab_type": "text"
      },
      "source": [
        "# Create Training Set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iefs3cyGcKZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv('/content/drive/My Drive/cs155/train.csv', index_col=0)\n",
        "train_df, y = add_fields(train_df, with_y=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_df, y, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WThA6X7r0aQi",
        "colab_type": "text"
      },
      "source": [
        "# Train Ensemble Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAR_kSyBPh3r",
        "colab_type": "code",
        "outputId": "fc86ba55-590d-495a-c052-3420a7e56261",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        }
      },
      "source": [
        "clf1 = GradientBoostingClassifier()\n",
        "clf2 = RandomForestClassifier()\n",
        "\n",
        "clf4 = AdaBoostClassifier()\n",
        "clf5 = LGBMClassifier()\n",
        "clf6 = XGBClassifier()\n",
        "\n",
        "linear_svc = LinearSVC()\n",
        "clf8 = BaggingClassifier()\n",
        "clf7 = CalibratedClassifierCV(linear_svc,\n",
        "                                        method='sigmoid',  #sigmoid will use Platt's scaling. Refer to documentation for other methods.\n",
        "                                        cv=3) \n",
        "\n",
        "\n",
        "estimators_list = [\n",
        "('cccv', [('gb', clf1), ('rf', clf2), ('ada', clf4),('lgbm', clf5),('xgb', clf6), ('cccv', clf7)]),\n",
        "('bagcv', [('gb', clf1), ('rf', clf2), ('ada', clf4),('lgbm', clf5),('xgb', clf6), ('bagcv', clf8)]),\n",
        "('linear_svm', [('gb', clf1), ('rf', clf2), ('ada', clf4),('lgbm', clf5),('xgb', clf6), ('linear_svm', linear_svc)])]\n",
        "\n",
        "\n",
        "for estimators in estimators_list:\n",
        "  eclf1 = VotingClassifier(estimators=estimators[1], voting='soft')\n",
        "  eclf1 = eclf1.fit(X_train, y_train)\n",
        "  print(\"\\n with\" + estimators[0] + '\\n')\n",
        "  print(eclf1.score(X_test, y_test))\n",
        "  y_probs = eclf1.predict_proba(X_test)\n",
        "  print(roc_auc_score(y_test, y_probs[:,1]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " withlinear_svm\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-8f99de3acff0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0meclf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meclf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n with\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mestimators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meclf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m   \u001b[0my_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meclf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_probs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \"\"\"\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvoting\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'soft'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0mmaj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 'hard' voting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36m_predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;34m\"\"\"Predict class probabilities for X in 'soft' voting.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         avg = np.average(self._collect_probas(X), axis=0,\n\u001b[0m\u001b[1;32m    260\u001b[0m                          weights=self._weights_not_none)\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36m_collect_probas\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_collect_probas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;34m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_collect_probas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;34m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'LinearSVC' object has no attribute 'predict_proba'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6roGjctZ5zN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ngk2gYpYPAk",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3ycfceXYPgO",
        "colab_type": "text"
      },
      "source": [
        "# Create .csv of Test Set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Z5-ZBScDPBr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_df = pd.read_csv('/content/drive/My Drive/CS 155/Kaggle 1/test.csv', index_col=0)\n",
        "# test_df, __ = add_fields(test_df, with_y=False)\n",
        "\n",
        "# eclf1 = eclf1.fit(train_df, y)\n",
        "# probbs = eclf1.predict_proba(test_df)\n",
        "# test_df['Predicted'] = probbs[:, 1]\n",
        "\n",
        "# header = [\"id\", \"Predicted\"]\n",
        "# test_df['id']=test_df.index\n",
        "# test_df.to_csv('output.csv', columns = header,index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ktr_gdpq3vZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}